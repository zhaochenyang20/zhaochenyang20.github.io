<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Understanding Gau GAN | I'LL TAKE YOU TO THE MOON</title><meta name="keywords" content="2022春季,科研,深度学习"><meta name="author" content="Eren Zhao"><meta name="copyright" content="Eren Zhao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="梵高再世....">
<meta property="og:type" content="article">
<meta property="og:title" content="Understanding Gau GAN">
<meta property="og:url" content="http://example.com/2022/06/04/CS/%E7%A7%91%E7%A0%94/%E5%A4%A7%E4%BA%8C%E5%AD%A6%E5%B9%B4/Gau%20GAN/index.html">
<meta property="og:site_name" content="I&#39;LL TAKE YOU TO THE MOON">
<meta property="og:description" content="梵高再世....">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Dave Hoefler (7uNro4xWMnk).jpg">
<meta property="article:published_time" content="2022-06-03T23:58:17.445Z">
<meta property="article:modified_time" content="2022-08-26T15:49:47.917Z">
<meta property="article:author" content="Eren Zhao">
<meta property="article:tag" content="2022春季">
<meta property="article:tag" content="科研">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Dave Hoefler (7uNro4xWMnk).jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://example.com/2022/06/04/CS/%E7%A7%91%E7%A0%94/%E5%A4%A7%E4%BA%8C%E5%AD%A6%E5%B9%B4/Gau%20GAN/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"麻了，找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Understanding Gau GAN',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2022-08-26 23:49:47'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/mouse.css"><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="I'LL TAKE YOU TO THE MOON" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}</style></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend.jpg'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">193</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">31</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/list-100/"><i class="fa-fw fas fa-music"></i><span> TODO</span></a></div><div class="menus_item"><a class="site-page" href="/projects/"><i class="fa-fw fas fa-video"></i><span> Projects</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Dave Hoefler (7uNro4xWMnk).jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">I'LL TAKE YOU TO THE MOON</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/list-100/"><i class="fa-fw fas fa-music"></i><span> TODO</span></a></div><div class="menus_item"><a class="site-page" href="/projects/"><i class="fa-fw fas fa-video"></i><span> Projects</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Understanding Gau GAN</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-06-03T23:58:17.445Z" title="发表于 2022-06-04 07:58:17">2022-06-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-26T15:49:47.917Z" title="更新于 2022-08-26 23:49:47">2022-08-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/">科研</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/CV/">CV</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>8分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Understanding Gau GAN"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>在本文中，我们将了解 GauGAN 算法如何在粒度级别上工作。<del>我们还将深入了解 Nvidia 为何在这些算法的使用上投入巨资。</del></p>
<p>我还想指出，在这篇文章中，我将主要关注 GauGAN，并避免在这篇文章中深入探讨 Pix2PixHD。这两种算法都生成图像并且有很多共同点，GauGAN 是最近的发展。因此，我将专注于 GauGAN，并且仅在存在与 GauGAN 明显不同的功能时才提及 Pix2PixHD。</p>
<h1 id="Conditional-GAN"><a href="#Conditional-GAN" class="headerlink" title="Conditional GAN"></a>Conditional GAN</h1><p>GAN 通常用于生成数据。通常会提供一个嘈杂的输入，网络将使用该输入来产生相关的输出。这种类型的 GAN 很有用，因为它不需要任何东西来生成除了随机噪声之外的数据，可以使用任何数字生成。</p>
<p>conditional GAN 通常采用特定输入来确定要生成的数据（换句话说，生成的数据<em>取决于</em>我们提供的输入）。例如，在 Gau GAN 中，输入是语义分割图，GAN 根据输入图像生成真实图像，如下例所示。</p>
<p><img src="https://lh6.googleusercontent.com/ukEqG1sR36rGRvmGgLIRc7mBnnEX3EwNzpthj0QcbF7nufrL_BV686B7oyvuVhVHHlpGvWGTGqDlW1-Dur_xXBRMzO2jFS5kJGtt92VC0wPBvh67tlZUmCNC_-bj_ehlnFGTu6X-" alt=""></p>
<p>同样，其他 conditional GAN 可能会创建：</p>
<ol>
<li>以前一帧为条件的视频帧。</li>
<li>以普通地图图像为条件的地形图图像。</li>
<li>以文字描述为条件的图像。</li>
</ol>
<h1 id="GauGAN-的架构"><a href="#GauGAN-的架构" class="headerlink" title="GauGAN 的架构"></a>GauGAN 的架构</h1><p>与任何其他生成对抗网络一样，GauGAN 包含一个鉴别器和一个生成器。特别是对于 GauGAN，Nvidia 通过使用特殊的 SPADE 块引入了一种称为 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1903.07291"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1903.07291">Spatially Adaptive Normalization</a></a> 的方法。此外，GauGAN 具有一个用于多模态合成的编码器。</p>
<p>生成器的输入包括：</p>
<ol>
<li>one-hot 编码语义分割图</li>
<li>边缘图（可选）</li>
<li>编码特征向量（可选）</li>
</ol>
<p>语义分割图基本上是 one-hot 编码的，因此我们有每个类的 one-hot 编码图。然后将这些地图深度连接起来。</p>
<p><img src="https://lh3.googleusercontent.com/pNrToYKjiVaf813KcsHg8tOMajij_IuDSJWJTGb_PM4TlT6u-owhyqyfAyl8poeh3G1a1B5qK4okBhgP9y3yH1b3Pd6DGxJIJQ_HoxWn6Q0Eqd5XMsSA9RMPfUAY0llxDEiQ4Aq4" alt=""></p>
<h2 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h2><p>GauGAN 的生成器是一个由 SPADE 块组成的全卷积解码器。SPADE 代表空间自适应归一化块。</p>
<div align=center>
<img width="500" src="https://lh3.googleusercontent.com/_umWygWhKYLJVItwSjxm3khQHz9TNsmTHJm6mHteV1mmBAB517YvqxkViMmP1tLRUVe88v63c7XcIZd_udrPsRi68yd4fYun9olXaM1Es0O3SX5pWhtrhzZDEyRAS7WuDmUtK23P"/>
</div>
<div align=center>GauGAN 生成器，Pix2PixHD 生成器的微型版本已用于比较。Pix2PixHD 依次具有卷积层、残差块和转置卷积。</div>

<p>GauGAN 的生成器和 Pix2PixHD 的生成器的架构存在重大差异。</p>
<p>首先，不涉及下采样层建立语义信息。相反，作者选择直接提供语义分割图作为每个 SPADE 块的输入（对应于网络中的不同级别）。</p>
<p>其次，与 Pix2PixHD 不同，上采样是通过最近邻调整大小而不是使用转置卷积层来执行的。转置卷积层由于容易在图像中产生 checkerboard artifacts 而失去了很多认可。从那以后，从业者开始转向不可学习的上采样，然后才是卷积层。作者只是顺应了这一趋势。</p>
<h3 id="SPADE-Normalization-Layer"><a href="#SPADE-Normalization-Layer" class="headerlink" title="SPADE Normalization Layer"></a><strong>SPADE Normalization Layer</strong></h3><p>在论文中，作者认为 batch normalization 等无条件归一化会导致语义信息的丢失。</p>
<p>传统 normalization 的框架为：</p>
<script type="math/tex; mode=display">
h=f\left(\mathbf{g} \cdot \frac{\mathbf{x}-\mu}{\sigma}+\mathbf{b}\right)</script><p>其中，各个归一化计算 $\sigma,\mu$ 的方法各有不同。</p>
<div align=center>
<img width="500" src="https://lh3.googleusercontent.com/JGY13318_vHN7o1AsmiyU5cJcKi93Nk1JmeykzCCE5wkzP_oeqxqMN0UH65yjUR25IumSZhbexJM4fFEEpDLDah23pWRwOUDXct6rD0u3qM14orw-bAGnhe-CG8s6CYUiiv8CU08"/>
</div>
<div align=center>In batch normalization, the statistics are computed over feature maps across all batches. In instance normalization, the statistics are computed over feature maps across a single image.</div>

<p>然而，在 SPADE 中，作者修改了 BN 方法（仍然计算小批量、每个特征图的统计数据），以便为特征图中的每个像素学习不同的参数集，而不是学习每个通道的参数集。通过将 BN 参数的数量增加到等于像素的数量来直接做到这一点。</p>
<p><strong>SPADE Generator Module</strong></p>
<div align=center>
<img src="https://lh4.googleusercontent.com/DRpCY_bOa4D2E3NfjwammC28AeDd26wCjrPg2egA2mJxlHdPgdN5YiRD9WDQz-AGg17Ly_FkGOffjr7nw1qSRmsF7O_v1dQZdV8qg1GeE3JRGt7uX2tSARJ_xhbxxHABoNoj77BJ" style="zoom:70%;"/>
</div>
<div align=center></div>

<p>To be disgused…</p>
<p> <strong>为什么 SPADE 有效？</strong></p>
<p>第一个原因是 GauGAN 的输入是一个语义图，它被进一步单热编码。这意味着 GAN 必须采用均匀值的区域，精确地为 1，并生成具有不同值的像素，以使它们看起来像一个真实的对象。为每个像素设置一组不同的批规范参数有助于解决此任务，而不是为特征图中的每个通道提供一组批规范参数。</p>
<p>作者还声称 SPADE 会导致更具<strong>辨别力</strong>的语义信息。为了支持他们的主张，他们拍摄了两张图片，两张都只有一个标签，一张是天空，另一张是草。将卷积应用于这两个图像会产生不同的值，但会产生统一的值。(Applying convolutions to both these images produce different values but uniform ones) 然后作者指出，实例范数的应用会将不同值但统一的特征图转换为仅包含零的相同值的特征图。这会导致语义信息的丢失。</p>
<p>然后他们继续展示 SPADE 和 Instance Norm 的输出在给定包含相同标签的语义图的情况下有何不同。</p>
<p><img src="https://lh3.googleusercontent.com/EsG7dU7Tw25uU8M1e-i95zeU5OTnDxHf4nCT7JNkWdOw_BqGrq20J1IQ3u8mLy4TVHMkHBPOjuKXlFrZOvtcPO9zcvOfP9BbMF0tdStzO8y7NLQqVymdaloCxOWoO_xrMqaSNz84" style="zoom:50%;" /></p>
<p>首先，作者声称信息由于标准化而被大量删除。然而，SPADE 和 Instance Norm 中的标准化步骤是相同的。它们不同的地方是重新缩放步骤。</p>
<p>其次，在 Pix2PixHD 中，Instance Norm 层的参数是不可学习的，Instance Norm 只是进行归一化（$\gamma$ 设置为 1 且 $\beta$ 设置为 0）。然而，在 GauGAN 中，SPADE 具有可学习的参数。</p>
<p>第三，Instance Norm 使用 1 的有效批量大小，而 SPADE 和 Batch Norm 都可以利用更大的批量大小（更大的批量大小导致更少的噪声统计估计）。</p>
<h2 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h2><p>通常，判别器是一个分类器网络，最后有完全连接的层，并产生一个介于 0 和 1 之间的单个输出，考虑到图像对判别器的真实程度。</p>
<p>multi-scale PatchGAN discriminator 是一个全卷积神经网络。它输出一个特征图，然后对其进行平均以获得图像的“真实性<em>”</em>分数。完全卷积有助于使 GAN 过程大小保持不变。</p>
<p><img src="https://lh6.googleusercontent.com/YA9bZD9o87cRTpEsIjba0tuCCfm3anbZAoMZZpoHpzpP-aaoYeCm4VyZeucswmlENvFFjmcdozCPeAhe_8g-0eP0SOJaEiXvH7tm_MIhSTv_ujMcwXbb14NdZAeLmmPR8j8EF3ra" style="zoom: 50%;" /></p>
<h3 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h3><p>与普通 GAN 不同，GauGAN 不采用随机噪声向量，而仅采用语义图。这意味着给定单个输入语义图，输出将始终是确定性的。这违背了图像合成的精神，因为产生不同输出的能力受到高度重视。为此，作者采用编码器以生成超出训练数据的数据。</p>
<p>编码器基本上是取一张图像，将图像编码成两个向量。这两个向量用作正态高斯分布的均值和标准差。然后从这个分布中采样一个随机向量，然后与输入语义映射一起连接作为生成器的输入。对不同的向量进行采样，合成结果也因此而多样化。</p>
<p><img src="https://lh3.googleusercontent.com/oODlvkIcHeV4-zhgN0HoL-VupxZHvL7krSt_TMMnKU-TdBvTYq6BO3A5ChngwOdpuYE1U639In-wMX-YRmFK0GFz5yX1zcVoCRRlcqtThnlQBtR-Ot8CFhEcFZTW_GwnXeXlp158" style="zoom: 60%;" /></p>
<h3 id="style-Guided-Image-Synthesis"><a href="#style-Guided-Image-Synthesis" class="headerlink" title="style-Guided Image Synthesis"></a>style-Guided Image Synthesis</h3><p>当我们从分布中采样不同的值（其均值和标准差由编码器预测）时，我们将能够探索数据的不同模式。例如，每个随机向量将生成具有相同语义布局但不同模态特征（如颜色、亮度等）的图像。</p>
<p><img src="https://lh5.googleusercontent.com/JEe1IXWhUJWGGgzoXuDVFa0z3aXwJRsveV-peuyK72isp0soNerTEVDf-2qR9bmVolinlWmgYDKWerkyCzyr-TJemeGKiUCfHo8J58E-oDt6UVKmqK8DijUlp8a6NlQt1g4hxAXP" style="zoom:50%;" /></p>
<h2 id="Loss-Function-And-Training"><a href="#Loss-Function-And-Training" class="headerlink" title="Loss Function And Training"></a>Loss Function And Training</h2><p><strong>Multiscale Adversarial Loss</strong></p>
<script type="math/tex; mode=display">
\begin{array}{l}
L_{D}=-\mathbb{E}_{(x, y) \sim p_{\text {data }}}[\min (0,-1+D(x, y))]-\mathbb{E}_{z \sim p_{z}, y \sim p_{\text {data }}}[\min (0,-1-D(G(z), y))], \\
L_{G}=-\mathbb{E}_{z \sim p_{z}, y \sim p_{\text {data }}} D(G(z), y),
\end{array}</script><p><strong>Feature Matching Loss</strong></p>
<script type="math/tex; mode=display">
L_{F M}\left(G, D_{k}\right)=\mathbb{E}_{s, x} \sum_{i=1}^{T} \frac{1}{N_{i}}\left[\left\|D_{k}^{(i)}(s, x)-D_{k}^{(i)}(s, G(s))\right\|_{1}\right]</script><script type="math/tex; mode=display">
L_{V G G}\left(G, D_{k}\right)=\mathbb{E}_{s, x} \sum_{i=1}^{5} \frac{1}{2^{i}}\left[\left\|V G G\left(x, M_{i}\right)-V G G\left(G(s), M_{i}\right)\right\|_{1}\right]</script><p>where $V G G(x, m)$ is the feature map m of $V G G 19$ when $x$ is the input. and $M={relu1_1,relu2_1,relu3_1,relu4_1,relu5_1}$</p>
<p><strong>Encoder Loss</strong></p>
<script type="math/tex; mode=display">
L_{K L D}=D_{k l}(q(z \mid x) \| p(z))</script><h1 id="How-to-train-and-transfer"><a href="#How-to-train-and-transfer" class="headerlink" title="How to train and transfer"></a>How to train and transfer</h1><p>这一部分将介绍训练细节，并了解如何在自己的自定义数据集上设置训练。另外，Nvidia 的开源实现在很多方面与官方文件中报道的不同。这是可以理解的，考虑到它自出版以来已经过去了将近一年。我会尽我所能指出这些差异。</p>
<h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>GauGAN 只使用一种尺寸和纵横比的图像进行训练。这意味着一旦训练，GauGAN 只能保证在与训练大小相同的图像上工作得最好。如果在推理过程中使用的图像太小或太大，预计输出会大大降低。</p>
<p>有多种方法可用于将图像调整或裁剪为 GauGAN 所需的大小。</p>
<h2 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h2><p>作者报告了 Glorot 初始化的使用，而此实现使用卷积层的默认 PyTorch 初始化，即 Kaiming 统一初始化。</p>
<h2 id="学习率策略"><a href="#学习率策略" class="headerlink" title="学习率策略"></a>学习率策略</h2><p>默认学习率设置为 0.0002。该实现还利用了<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/7240-gans-trained-by-a-two-time-scale-update-rule-converge-to-a-local-nash-equilibrium.pdf">两个时间尺度更新规则学习策略</a>，为生成器和判别器选择了不同的学习率。通常，生成器的学习率保持低于判别器，以使生成器通过缓慢学习来表现更好，从而使学习更加稳定。</p>
<p>对于 epoch 总数的前半部分，训练学习率选项<code>lr</code>保持在初始化时的值不变。判别器和生成器都以这种学习率进行训练。在后半部分，学习率选项<code>lr</code>线性衰减到零，每个 epoch 都会更新。对于每次更新，判别<code>lr * 2</code>器学习率设置为，而生成器学习率设置为<code>lr / 2</code>。</p>
<h2 id="批量大小"><a href="#批量大小" class="headerlink" title="批量大小"></a>批量大小</h2><p>批量大小通常取决于尝试合成的图像大小。GauGAN 可能需要大量 GPU 资源才能正常工作。在批量大小为 1 的大小为 768 x 576 的图像上训练默认的 GauGAN 大约需要 12 GB 的 GPU 内存。Nvidia 开源实现的自述文件内容如下：</p>
<blockquote>
<p><strong>要重现论文中报告的结果，你需要一台配备 8 个 V100 GPU 的 NVIDIA DGX1 机器</strong></p>
</blockquote>
<p>这相当于 128 GB 的显存…</p>
<h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>Adam 优化器用于生成器和鉴别器。  $β_1$ 和 $β_2$ 分别设置为 0.5 和 0.999。</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2022%E6%98%A5%E5%AD%A3/">2022春季</a><a class="post-meta__tags" href="/tags/%E7%A7%91%E7%A0%94/">科研</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-62b11572b25ab3ab" async="async"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/06/Lecture/2022%20Spring/statistic/"><img class="prev-cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Byron Johnson (ec2SZSGPwJA).jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Oscar Rodrigo Hernandez Panczenko (P0GQ95huhBo).jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Statistics</div></div></a></div><div class="next-post pull-right"><a href="/2022/05/25/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%94%E9%83%A8/"><img class="next-cover" src="https://zhaochenyang20.github.io/pic/embed/5_31_1.jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Oscar Rodrigo Hernandez Panczenko (P0GQ95huhBo).jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">清华园日记——第五部</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/05/06/CS/%E7%A7%91%E7%A0%94/%E5%A4%A7%E4%BA%8C%E5%AD%A6%E5%B9%B4/Enhancing%20photorealism%20enhancement/" title="Enhancing photorealism enhancement"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Bjorn Snelders (PeLkhi_B3wI).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-06</div><div class="title">Enhancing photorealism enhancement</div></div></a></div><div><a href="/2022/05/17/Lecture/2022%20Spring/binaryDivdence/" title="深度学习基础"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by John O'Nolan (6f_ANCcbj3o).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-17</div><div class="title">深度学习基础</div></div></a></div><div><a href="/2022/03/15/Lecture/2022%20Spring/Introduction_to_AI/" title="Introduction to Artificial Intelligence"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Alexander Slattery (LI748t0BK8w).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-15</div><div class="title">Introduction to Artificial Intelligence</div></div></a></div><div><a href="/2022/05/24/Lecture/2022%20Spring/Reinforcement/" title="重力四子棋"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by JD X (y0qwRko4r9w).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-24</div><div class="title">重力四子棋</div></div></a></div><div><a href="/2022/06/06/Lecture/2022%20Spring/deep_learning/" title="Segement Me If U Can"><img class="cover" src="https://pic.imgdb.cn/item/61ed14292ab3f51d911d280f.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-06</div><div class="title">Segement Me If U Can</div></div></a></div><div><a href="/2022/03/23/Lecture/2022%20Spring/Input%20method/" title="How Do We Train An Input Method"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Johny Goerend (f01YC_nH3XE).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-23</div><div class="title">How Do We Train An Input Method</div></div></a></div><div><a href="/2022/03/08/CS/%E7%A7%91%E7%A0%94/%E5%A4%A7%E4%BA%8C%E5%AD%A6%E5%B9%B4/Fully%20Convolutional%20Networks%20for%20Semantic%20Segmentation/" title="Fully Convolutional Networks for Semantic Segmentation 阅读笔记"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Cassie Boca (EiGCgdLd_C8).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-08</div><div class="title">Fully Convolutional Networks for Semantic Segmentation 阅读笔记</div></div></a></div><div><a href="/2022/01/20/CS/%E7%A7%91%E7%A0%94/%E5%A4%A7%E4%BA%8C%E5%AD%A6%E5%B9%B4/equivariant/" title="Euivariant & Invariant"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Erik Ringsmuth (d3a6KbEmsE8).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-20</div><div class="title">Euivariant & Invariant</div></div></a></div><div><a href="/2022/01/15/CS/%E7%A7%91%E7%A0%94/%E5%A4%A7%E4%BA%8C%E5%AD%A6%E5%B9%B4/Dive%20Into%20Deep%20Learning%20Part%201/" title="Dive Into Deep Learning Chapter 1~3"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Erik Ringsmuth (d3a6KbEmsE8).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-15</div><div class="title">Dive Into Deep Learning Chapter 1~3</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Conditional-GAN"><span class="toc-number">1.</span> <span class="toc-text">Conditional GAN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GauGAN-%E7%9A%84%E6%9E%B6%E6%9E%84"><span class="toc-number">2.</span> <span class="toc-text">GauGAN 的架构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Generator"><span class="toc-number">2.1.</span> <span class="toc-text">Generator</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SPADE-Normalization-Layer"><span class="toc-number">2.1.1.</span> <span class="toc-text">SPADE Normalization Layer</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Discriminator"><span class="toc-number">2.2.</span> <span class="toc-text">Discriminator</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#encoder"><span class="toc-number">2.2.1.</span> <span class="toc-text">encoder</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#style-Guided-Image-Synthesis"><span class="toc-number">2.2.2.</span> <span class="toc-text">style-Guided Image Synthesis</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Loss-Function-And-Training"><span class="toc-number">2.3.</span> <span class="toc-text">Loss Function And Training</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#How-to-train-and-transfer"><span class="toc-number">3.</span> <span class="toc-text">How to train and transfer</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text">预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">3.2.</span> <span class="toc-text">权重初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%8E%87%E7%AD%96%E7%95%A5"><span class="toc-number">3.3.</span> <span class="toc-text">学习率策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%B9%E9%87%8F%E5%A4%A7%E5%B0%8F"><span class="toc-number">3.4.</span> <span class="toc-text">批量大小</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">3.5.</span> <span class="toc-text">优化器</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background: ＃0096FF"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Eren Zhao</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><script type="text/javascript" id="maid-script" src="https://unpkg.com/mermaid@undefined/dist/mermaid.min.js?v=undefined"></script><script>if (window.mermaid) {
  var options = JSON.parse(document.getElementById('maid-script').getAttribute('mermaidoptioins'));
  mermaid.initialize(options);
}</script></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库正在艰难运行</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '978121c7b834efdd76be',
      clientSecret: '59b40e8f39a1c33db5a2c891771086164b9575c4',
      repo: 'zhaochenyang20.github.io',
      owner: 'zhaochenyang20',
      admin: ['zhaochenyang20'],
      id: '6d102c70bdb4046dd3244c46b1b7cecc',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/"});</script></body></html>