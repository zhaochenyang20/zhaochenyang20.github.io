<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Statistics | 求道之人，不问寒暑</title><meta name="keywords" content="2022春季,数学"><meta name="author" content="Eren Zhao"><meta name="copyright" content="Eren Zhao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="梁老师教的蛮好，你把他 PF 了干嘛？">
<meta property="og:type" content="article">
<meta property="og:title" content="Statistics">
<meta property="og:url" content="http://example.com/2022/06/06/Lecture/2022%20Spring/statistic/index.html">
<meta property="og:site_name" content="求道之人，不问寒暑">
<meta property="og:description" content="梁老师教的蛮好，你把他 PF 了干嘛？">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg">
<meta property="article:published_time" content="2022-06-06T06:31:12.104Z">
<meta property="article:modified_time" content="2022-08-26T16:20:11.687Z">
<meta property="article:author" content="Eren Zhao">
<meta property="article:tag" content="2022春季">
<meta property="article:tag" content="数学">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://example.com/2022/06/06/Lecture/2022%20Spring/statistic/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"麻了，找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Statistics',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2022-08-27 00:20:11'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/mouse.css"><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="求道之人，不问寒暑" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}</style></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend.jpg'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">192</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">31</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/list-100/"><i class="fa-fw fas fa-music"></i><span> TODO</span></a></div><div class="menus_item"><a class="site-page" href="/projects/"><i class="fa-fw fas fa-video"></i><span> Projects</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">求道之人，不问寒暑</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/list-100/"><i class="fa-fw fas fa-music"></i><span> TODO</span></a></div><div class="menus_item"><a class="site-page" href="/projects/"><i class="fa-fw fas fa-video"></i><span> Projects</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Statistics</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-06-06T06:31:12.104Z" title="发表于 2022-06-06 14:31:12">2022-06-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-26T16:20:11.687Z" title="更新于 2022-08-27 00:20:11">2022-08-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B/">课程</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B/%E6%A6%82%E7%BB%9F/">概统</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>26分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Statistics"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="readme"><a href="#readme" class="headerlink" title="readme"></a>readme</h1><ul>
<li>梁衡老师的概统讲的很好，<del>少数我想线下听的课</del>，可惜也没好好听，而且记了 PF，就当复习个快乐，学习没那么 targeted</li>
<li>我总结下每一章比较有意思的地方，这一部分是统计</li>
</ul>
<h1 id="统计学基本概念"><a href="#统计学基本概念" class="headerlink" title="统计学基本概念"></a>统计学基本概念</h1><ul>
<li>样本均值</li>
</ul>
<blockquote>
<p>设 $x<em>{1}, x</em>{2}, \cdots, x_{n}$ 是来自某个总体的样本, $\bar{x}$ 为样本均值,</p>
<ol>
<li>若总体分布为 $N\left(\mu, \sigma^{2}\right)$, 则 $\bar{x} \sim N\left(\mu, \frac{\sigma^{2}}{n}\right)$;</li>
<li>若总体分布不是正态分布或根本末知, $E(X)=\mu, \operatorname{Var}(X)=\sigma^{2}$, 则 $n$ 较大时, $\bar{x}$ 的渐近分布为 $N\left(\mu, \frac{\sigma^{2}}{n}\right)$, 常记为 $\bar{x} \dot{\sim} N\left(\mu, \frac{\sigma^{2}}{n}\right)$<br>(中心极限定理）</li>
<li>实际上，如果 X 的分布本身不是正态分布，则 $ E(\bar{x})=\mu,Var(\bar{x})= \frac{\sigma^{2}}{n}$ 仍然成立，只是不严格正态。而 n 足够大的时候，渐进为正态分布</li>
</ol>
</blockquote>
<ul>
<li>样本方差</li>
</ul>
<blockquote>
<p>样木本方差 $s^{2}=\frac{1}{n-1} \sum<em>{i=1}^{n}\left(x</em>{i}-\bar{x}\right)^{2}$</p>
<p>设总体 $X$ 具有二阶矩, 即 $E(X)=\mu, \operatorname{Var}(X)=\sigma^{2}&lt;+\infty$, $x<em>{1}, x</em>{2}, \cdots, x_{n}$ 为从该总体得到的样本, $\bar{x}$ 和 $s^{2}$ 分别是样本均值和样本方差, 则 $E(\bar{x})=\mu, \operatorname{Var}(\bar{x})=\frac{\sigma^{2}}{n}, E\left(s^{2}\right)=\sigma^{2}$ （无偏估计）</p>
<blockquote>
<p>注意，$s^2$ 是 $\sigma^2$ 的无偏估计，但是并不意味着 $s$ 是 $\sigma$ 的无偏估计</p>
<p> Var $(S)=E\left(S^{2}\right)-E(S)^{2}=\sigma^{2}-E(S)^{2}&gt;0$, 所以 $E(S)&lt;\sigma$ </p>
</blockquote>
<p>$X<em>{1}, X</em>{2}, \cdots, X_{n}$ 是来自均匀总体 $X \sim U(-a, a)$ 的样本, 用矩估计法估计参数 $a$。</p>
<p>$\operatorname{Var}(X)=\frac{a^{2}}{3}$, 令 $\frac{a^{2}}{3}=s^{2} \Rightarrow \hat{a}=\sqrt{3} s$，但不是无偏估计。</p>
<p>样本 $k$ 阶原点矩 $a<em>{k}=\frac{1}{n} \sum</em>{i=1}^{n} x<em>{i}^{k}$, 样本 $k$ 阶中心矩 $b</em>{k}=\frac{1}{n} \sum<em>{i=1}^{n}\left(x</em>{i}-\bar{x}\right)^{k}$</p>
</blockquote>
<ul>
<li>次序统计量</li>
</ul>
<blockquote>
<p>对于次序统计量，利用习题课 1 上的 trick 即可</p>
</blockquote>
<ul>
<li>三大分布</li>
</ul>
<blockquote>
<ol>
<li>$X<em>{1}, X</em>{2}, \cdots, X<em>{n}$ 独立同分布, 服从 $N(0,1)$ 则 $Y=X</em>{1}{ }^{2}+\cdots+X<em>{n}{ }^{2} \sim \chi</em>{n}{ }^{2}$ 或 $\chi^{2}(n)$, 称为自由度为 $n$ 的 $\chi^{2}$ 分布 —— $n$ 个独立同分布的标准正态分布之和为 $n$ 自由度的卡方分布</li>
<li>$t$ 分布 $X<em>{1} \sim N(0,1), X</em>{2} \sim \chi<em>{n}^{2}, X</em>{1}, X<em>{2}$ 相互独立 $t=\frac{X</em>{1}}{\sqrt{X_{2} / n}} \sim t(n)$, 称为自由度为 $n$ 的 $t$ 分布 —— 标准正态分布除以独立的 $n$ 自由度卡方分布除 $n$ 开根为 $n$ 自由度的 $t$ 分布</li>
<li>$F$ 分布 $X<em>{1}, X</em>{2}$ 相互独立, $X<em>{1} \sim \chi</em>{m}{ }^{2}, X<em>{2} \sim \chi</em>{n}{ }^{2},F=\frac{X<em>{1} / m}{X</em>{2} / n} \sim F(m, n)$ 称为自由度为  $m$  与 $n$ 的 $F$ 分布</li>
</ol>
<p>举个例子，构造分布：</p>
<p>设 $X<em>{1}, X</em>{2}, \ldots, X<em>{8}$ 为相互独立的 $N(0,1)$ 随机变量, 则 $P\left(\frac{X</em>{1}-X<em>{2}}{\left|X</em>{1}+X<em>{2}+\cdots+X</em>{8}\right|} \geq ?\right)= 0.05$</p>
<p>解: $X<em>{1}-X</em>{2} \sim N(0,2), \quad X<em>{1}+X</em>{2}+\ldots+X_{8} \sim N(0,8)$</p>
<p>$\operatorname{Cov}\left(X<em>{1}-X</em>{2}, X<em>{1}+X</em>{2}\right)=0$</p>
<p>构造 F 分布：</p>
<p>$\frac{\left(X<em>{1}-X</em>{2}\right)^{2} / 2}{\left(X<em>{1}+X</em>{2}+\ldots+X<em>{8}\right)^{2} / 8} \sim F(1,1), \quad P\left(\frac{\left(X</em>{1}-X<em>{2}\right)^{2} / 2}{\left(X</em>{1}+X<em>{2}+\ldots+X</em>{8}\right)^{2} / 8} \geq F_{0.9}(1,1)\right)=0.1$</p>
<p>$P\left(\frac{\left(X<em>{1}-X</em>{2}\right) / \sqrt{2}}{\left|X<em>{1}+X</em>{2}+X<em>{3}+X</em>{4}\right| / 2 \sqrt{2}} \geq \sqrt{F<em>{0.9}(1,1)}\right)=0.05 \Rightarrow P\left(\frac{X</em>{1}-X<em>{2}}{\left|X</em>{1}+X<em>{2}+X</em>{3}+X<em>{4}\right|} \geq \frac{\sqrt{F</em>{0.9}(1,1)}}{2}\right)=0.05$</p>
<p>$P\left(\frac{X<em>{1}-X</em>{2}}{\left|X<em>{1}+X</em>{2}+X<em>{3}+X</em>{4}\right|} \geq \sqrt{10}\right)=0.05$</p>
<p>构造 T 分布：</p>
<p>$\frac{\left(X<em>{1}-X</em>{2}\right) / \sqrt{2}}{\sqrt{\left(X<em>{1}+X</em>{2}+\ldots+X<em>{8}\right)^{2} / 8}} \sim t(1), \quad P\left(\frac{\left(X</em>{1}-X<em>{2}\right) / \sqrt{2}}{\left|X</em>{1}+X<em>{2}+\ldots+X</em>{8}\right| / \sqrt{8}} \geq t_{0.95}(1)\right)=0.05$</p>
<p>$P\left(\frac{X<em>{1}-X</em>{2}}{\left|X<em>{1}+X</em>{2}+X<em>{3}+X</em>{4}\right|} \geq \frac{t<em>{0.95}(1)}{2}\right)=0.05, \quad P\left(\frac{X</em>{1}-X<em>{2}}{\left|X</em>{1}+X<em>{2}+X</em>{3}+X_{4}\right|} \geq 3.16\right)=0.05$</p>
</blockquote>
<ul>
<li>分布反演</li>
</ul>
<blockquote>
<p>设随机变量 $\xi$ 服从自由度为 $(1,1)$ 的 $F$ 分布, 则 $P(\xi \leq 1)=(\quad)$ </p>
<p>设 $X<em>{1} \sim \chi^{2}(1), X</em>{2} \sim \chi^{2}(1), X<em>{1} 、 X</em>{2}$ 相互独立, 所以 </p>
<p>$P\left(X<em>{1} \leq X</em>{2}\right)=P\left(X<em>{1} \geq X</em>{2}\right)=\frac{1}{2}, \quad P(\xi \leq 1)=P\left(\frac{X<em>{1}}{X</em>{2}} \leq 1\right)=P\left(X<em>{1} \leq X</em>{2}\right)=\frac{1}{2}$</p>
<hr>
<p>设随机变量 $T$ 服从自由度为 1 的 $t$ 分布, 则 $P(T \leq 1)=(\quad)$ </p>
<p>设 $X, Y$ 相互独立, 且均服从 $N(0,1)$, 则 $\frac{X}{|Y|}$ 服从自由度为 1 的 $t$ 分布, 于是</p>
<p>$\begin{array}{l}<br>P(T \leq 1)=P(T \leq 0)+P(0&lt;T&lt;1)=0.5+\frac{1}{2} P(|T|&lt;1) \<br>=0.5+0.5 \times P\left(X^{2}&lt;Y^{2}\right)=0.5+0.5 \times 0.5=0.75<br>\end{array}$</p>
<blockquote>
<p>这个稍微需要理解下，$X$ 为负数时，$T$ 必小于 0，此即 $P(T\le0)=\frac{1}{2}$。而 $P(0\le T\le 1)=P(X\ge 0)\times p(X\le |Y|)=\frac{1}{2}\times P(X^2\le Y^2)=\frac{1}{4}$</p>
<p>还有一个想法，$P(X\le |Y|$ 按照全概率公式，分为 $P(Y\le 0)<br>\times P(X\le -Y|Y \le 0)+P(Y\ge 0)\times P(X\le Y|Y \ge 0)$，这个方法很简单，重点是不要忘了全概率公式应该乘的是条件概率。</p>
</blockquote>
</blockquote>
<h1 id="参数点估计的方法与评价"><a href="#参数点估计的方法与评价" class="headerlink" title="参数点估计的方法与评价"></a>参数点估计的方法与评价</h1><ul>
<li>矩估计</li>
</ul>
<blockquote>
<p>尽量用低阶矩来估计参数</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26614750">极大似然估计</a></li>
</ul>
<blockquote>
<p> 对于二元函数 $p(x ,\theta)$ 输入有两个：$\mathrm{x}$ 表示某一个具体的数据，$\theta$ 表示模型的参数</p>
<p>如果 $\theta$ 是已知确定的，$x$ 是变量, 即为概率函数(probability function)，它描述对于不同样本点 $x$, 其出现概率是多少</p>
<p>如果 $x$ 是已知确定的，$\theta$ 是变量，这个函数叫做似然函数(likelihood function)，它描述对于不同的模型参数，出现 $x$ 这个样本点的概率是多少</p>
<p><strong>我们想办法让观察样本出现的概率最大</strong>，就是极大似然估计</p>
</blockquote>
<ul>
<li>对数似然函数</li>
</ul>
<blockquote>
<p>$\ln (L(\theta))$，由于 $\ln x$ 是 $x$ 的单调函数，使得 $\ln (L(\theta))$ 与 $L(\theta)$ 达到最大的 $\theta$ 相同，常利用对数似然函数求解极大似然估计。</p>
</blockquote>
<ul>
<li>泊松分布与全损指数分布的极大似然估计</li>
</ul>
<blockquote>
<p>$\hat{\lambda<em>{Poisson}}=\overline{\boldsymbol{x}}$，$\hat{\lambda</em>{Exponential}}=\frac{1}{\bar{x}}$</p>
</blockquote>
<ul>
<li>有损指数分布的极大似然估计</li>
</ul>
<blockquote>
<p>设寿命小于 $T$ 的 $r$ 个观测值为 $x<em>{1}, x</em>{2}, \cdots, x<em>{r}$, 对应的 $r$ 个 $y</em>{k}$ 的值</p>
<p>剩下的 $n-r$ 个 $y_{k}$ 的取值均为 $T$, 每一个发生概率为 $P(X \geq T)=e^{-\lambda T}$</p>
<p>似然函数 $L\left(\lambda ; y<em>{1}, y</em>{2}, \cdots, y<em>{n}\right)=\lambda^{r} e^{-\lambda\left(x</em>{1}+x<em>{2}+\cdots+x</em>{r}\right)} \cdot e^{-\lambda(n-r) T}$</p>
<p>$\ln L(\lambda)=r \ln \lambda-\lambda\left(x<em>{1}+x</em>{2}+\cdots+x_{r}\right)-\lambda(n-r) T$</p>
<p>$\begin{array}{l}<br>\frac{d \ln L(\lambda)}{d \lambda}=\frac{r}{\lambda}-\left(x<em>{1}+x</em>{2}+\cdots+x<em>{r}+(n-r) T\right)=0 \<br>\Rightarrow \hat{\lambda}=r /\left[x</em>{1}+\cdots+x_{r}+(n-r) T\right]<br>\end{array}$</p>
</blockquote>
<ul>
<li>均匀分布的极大似然估计</li>
</ul>
<blockquote>
<p>参数 $a, b$ 的极大似然估计 $\hat{a}=\min \left(\boldsymbol{X}<em>{1}, \boldsymbol{X}</em>{2} \cdots, \boldsymbol{X}<em>{n}\right), \hat{b}=\max \left(\boldsymbol{X}</em>{1}, \boldsymbol{X}<em>{2} \cdots, \boldsymbol{X}</em>{n}\right)$</p>
<p><strong>极大似然估计得到的不一定是无偏估计</strong></p>
</blockquote>
<ul>
<li>柯西分布的极大似然估计</li>
</ul>
<blockquote>
<p>Cauchy 分布随机变量的期望不存在, 因此不能用矩估计法对参数 $\theta$ 进行估计</p>
<p>设 $x<em>{1}, x</em>{2}, \cdots, x_{n}$ 为来自该总体的样本观测值</p>
<p>似然函数 $L(\theta)=\prod<em>{k=1}^{n} f\left(x</em>{k} ; \theta\right)=\prod<em>{k=1}^{n} \frac{1}{\pi\left[1+\left(x</em>{k}-\theta\right)^{2}\right]}$</p>
<p>对数似然函数 $\ln L(\theta)=\sum<em>{k=1}^{n}-\left(\ln \pi+\ln \left(1+\left(x</em>{k}-\theta\right)^{2}\right)\right)$</p>
<p>将上式对 $\theta$ 求导，并令其等于 0 </p>
<p>$\frac{d \ln L(\theta)}{d \theta}=-\sum<em>{k=1}^{n} \frac{x</em>{k}-\theta}{1+\left(x_{k}-\theta\right)^{2}}=0$</p>
<p>方程无法的到解析解，需要用一定的计算方法近似求解</p>
</blockquote>
<ul>
<li>相合估计</li>
</ul>
<blockquote>
<p>定理: 设 $\hat{\theta}<em>{n}=\hat{\theta}</em>{n}\left(x<em>{1}, x</em>{2}, \cdots, x<em>{n}\right)$ 是 $\theta$ 的一个估计量, 若 $\lim </em>{n \rightarrow \infty} E\left(\hat{\theta}<em>{n}\right)=\theta \quad \lim </em>{n \rightarrow \infty} \operatorname{Var}\left(\hat{\theta}<em>{n}\right)=0$，则 $\hat{\theta}</em>{n}$ 是参数 $\theta$ 的相合估计。</p>
</blockquote>
<ul>
<li>无偏性与有效性</li>
</ul>
<blockquote>
<p>无偏性，保证没有系统偏差</p>
<p>设 $\theta \in \Theta$ 为末知参数, $\hat{\theta}=\hat{\theta}\left(x<em>{1}, x</em>{2}, \cdots, x_{n}\right)$ 是 $\theta$ 的一个估计量，若对任意 $\theta \in \Theta$ 有 $E(\hat{\theta})=\theta$，则称 $\hat{\theta}$ 是参数 $\theta$ 的无偏估计。</p>
<p>有效性，希望估计围绕参数波动的幅度越小越好。</p>
<p>设 $\hat{\theta}<em>{1}, \hat{\theta}</em>{2}$ 是参数 $\theta$ 的无偏估计，如果对任意 $\theta \in \Theta$ 有 $\operatorname{Var}\left(\hat{\theta}<em>{1}\right) \leq \operatorname{Var}\left(\hat{\theta}</em>{2}\right)$，且至少有一个 $\theta \in \Theta$ 使得上述不等号严格成立，则称 $\hat{\theta}<em>{1}$ 比 $\hat{\theta}</em>{2}$ 有效。</p>
<p>简单的应用：样本数量的增加会改善估计。</p>
</blockquote>
<ul>
<li><strong>极大似然估计</strong>得到的不一定是无偏估计</li>
</ul>
<blockquote>
<p>$X<em>{1}, X</em>{2}, \cdots, X<em>{n}$ 是来自均匀总体 $U(0, \theta)$ 的样本，参数 $\theta$ 的极大似然估计量 $\tilde{\theta}=\max </em>{1 \leq k \leq n} X_{k}$, 考查无偏性。</p>
<p>计算 $\tilde{\theta}=\max <em>{1 \leq k \leq n} X</em>{k}$ 的分布函数，当 $0 \leq y \leq \theta$ 时, 由样本的独立同分布性质，可知其分布函数（CDF）为</p>
<script type="math/tex; mode=display">
F_{\dot{\theta}}(y)=P(\tilde{\theta} \leq y)=P\left(\max _{1 \leq k \leq n} X_{k} \leq y\right)=\prod_{k=1}^{n} P\left(X_{k} \leq y\right)=\left(\frac{y}{\theta}\right)^{n}</script><p>$\tilde{\theta}=\max <em>{1 \leq k \leq n} X</em>{k}$ 的分布函数 $F<em>{\tilde{\theta}}(y)=\left{\begin{array}{c}0, y<0 \\ \left(\frac{y}{\theta}\right)^{n}, 0 \leq y \leq \theta, \\ 1, y>\theta\end{array}\right.$<br>于是 $\tilde{\theta}$ 的概率密度（PDF）为 $f</em>{\tilde{\theta}}(y)=\left{\begin{array}{c}\frac{n}{\theta^{n}} y^{n-1}, y \in[0, \theta] \ 0, \text { 其它 }\end{array} \quad\right.$ 因此, 我们有</p>
<script type="math/tex; mode=display">
\begin{aligned}
E(\tilde{\theta}) &=\int_{-\infty}^{+\infty} y f_{\tilde{\theta}}(y) d y=\int_{0}^{\theta} y \frac{n}{\theta^{n}} y^{n-1} d y \\
&=\frac{n}{\theta^{n}} \int_{0}^{\theta} y^{n} d y=\left.\frac{n}{\theta^{n}} \cdot \frac{y^{n+1}}{n+1}\right|_{0} ^{\theta}=\frac{n}{n+1} \theta
\end{aligned}</script><p>$E(\tilde{\theta})=E\left(\max <em>{1 \leq k \leq n} X</em>{k}\right)=\frac{n}{n+1} \theta$，统计量 $\max <em>{1 \leq k \leq n} X</em>{k}$ 不是参数 $\theta$ 的无偏估计，$\frac{n+1}{n} \max <em>{1 \leq k \leq n} X</em>{k}$ 则为无偏估计，称为无偏校正。</p>
</blockquote>
<ul>
<li>正态分布的极大似然估计</li>
</ul>
<blockquote>
<p>所以参数 $\mu$ 和 $\sigma^{2}$ 的极大似然估计量为 $\hat{\mu}=\bar{X}, \hat{\sigma}^{2}=\frac{1}{n} \sum<em>{i=1}^{n}\left(X</em>{i}-\bar{X}\right)^{2}$（与 $s^{2}=\frac{1}{n-1} \sum<em>{i=1}^{n}\left(x</em>{i}-\bar{x}\right)^{2}$ 完全没关系，而 $s^2$ 是 $\sigma^2$ 的无偏估计）</p>
<p>注意，估计的不是 $\sigma$，而是 $\sigma^2$</p>
</blockquote>
<ul>
<li>均方误差</li>
</ul>
<blockquote>
<script type="math/tex; mode=display">
\begin{aligned}
\operatorname{MSE}(\hat{\theta})=E(\hat{\theta}-\theta)^{2} &=E[(\hat{\theta}-E(\hat{\theta}))+(E(\hat{\theta})-\theta)]^{2} \\
&=\operatorname{Var}(\hat{\theta})+(\boldsymbol{E}(\hat{\theta})-\theta)^{2}
\end{aligned}</script><p>若 $\hat{\theta}$ 是参数 $\theta$ 的无偏估计, 则 $\operatorname{MSE}(\hat{\theta})=\operatorname{Var}(\hat{\theta})$</p>
<p>注: 很多时候, 无偏估计的均方误差会小于有偏估计的均方误差, 但二者之间并没有严格的对应关系，例如书上 324 页（第三版 286-287 页）例 6.4.1 即给出一个有偏估计均方误差小于无偏估计均方误差的实例。</p>
</blockquote>
<h1 id="参数区间估计"><a href="#参数区间估计" class="headerlink" title="参数区间估计"></a>参数区间估计</h1><ul>
<li>置信系数</li>
</ul>
<blockquote>
<p>抽取 n 个样本得到一个区间估计, 将这样的估计重复足够多次, 至少 $1-\alpha$ 比例的估计区间包含真实的 $\mu$ 值。这里置信系数是 $0.9544$, 即大约 $95.44 \%$ 估计区间包含真实的 $\mu$ 值。</p>
<p>或者说，这种抽样方法得到的这些区间至少有 $1-\alpha$ 的概率包含真实的 $\mu$ 值。</p>
<p>末知参数本身是确定的值, 不带有随机性。随机性是由区间引入的。</p>
</blockquote>
<ul>
<li>下侧 $\alpha$ 分位数</li>
</ul>
<blockquote>
<p>$\Phi(d)=1-\frac{\alpha}{2}, \quad F(c)=\frac{\alpha}{2} \quad \Rightarrow \quad d=\Phi^{-1}\left(1-\frac{\alpha}{2}\right), \quad c=\Phi^{-1}\left(\frac{\alpha}{2}\right)$</p>
<p>标准正态分布的 $1-\frac{\alpha}{2}$ 分位数和 $\frac{\alpha}{2}$ 分位数，$d=u<em>{1-\frac{\alpha}{2}}, \quad c=u</em>{\frac{\alpha}{2}}=-u_{1-\frac{\alpha}{2}}$</p>
<p>在此基础上，可以看出 $P(u<em>{\frac{\alpha}{2}}\le Z\le u</em>{1-\frac{\alpha}{2}})=P(|Z|\le u<em>{1-\frac{\alpha}{2}})，u</em>{\alpha}=-u_{1-\alpha}$</p>
<p>最主要的还是理解分位数的反函数定义，小于 $\alpha$ 分位点的概率是 $\alpha$</p>
<p>标准正态分布的 $\alpha$ 分位点记为 $u_{\alpha}$</p>
<p>$n$ 个自由度的 $\chi^{2}$ 分布的 $\alpha$ 分位点记为 $\chi_{\alpha}^{2}(n)$</p>
<p>$n$ 个自由度的 $t$ 分布的 $\alpha$ 分位点记为 $t_{\alpha}(n)$</p>
<p>$(m, n)$ 自由度的 $F$ 分布的 $\alpha$ 分位点记为 $F_{\alpha}(m, n)$</p>
<p>$X$ 为一连续分布随机变量, 如果 $P(X \geq a)=\alpha$, $a$ 称为上侧 $\alpha$ 分位数</p>
</blockquote>
<ul>
<li>统计抽样定理</li>
</ul>
<blockquote>
<p>设 $x<em>{1}, x</em>{2}, \cdots, x<em>{n}$ 是来自正态总体 $N\left(\mu, \sigma^{2}\right)$ 的样本, 其样本均值和样本方差分别为:<br>$\bar{x}=\frac{x</em>{1}+x<em>{2}+\cdots+x</em>{n}}{n}$ 和 $s^{2}=\frac{1}{n-1} \sum<em>{i=1}^{n}\left(x</em>{i}-\bar{x}\right)^{2}$, 则有</p>
<ol>
<li>$\bar{x}$ 与 $s^{2}$ 相互独立</li>
<li>$\bar{x} \sim N\left(\mu, \frac{\sigma^{2}}{n}\right)$</li>
<li>$\frac{(n-1) \cdot s^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)$</li>
</ol>
</blockquote>
<ul>
<li>方差已知区间估计</li>
</ul>
<blockquote>
<p>总体 $N\left(\mu, \sigma^{2}\right), \sigma^{2}$ 已知，$\mu$ 末知，$x<em>{1}, x</em>{2}, \cdots, x_{n}$ 是简单随机样本, 求 $\mu$ 的1- $\alpha$ 置信区间</p>
<p>$\frac{\bar{x}-\mu}{\sqrt{\frac{\sigma^{2}}{n}}}$ 可作为枢轴量, $Z=\frac{\bar{x}-\mu}{\sqrt{\frac{\sigma^{2}}{n}}}=\frac{\sqrt{n}(\bar{x}-\mu)}{\sigma} \sim N(0,1)$</p>
<p>构造出枢轴量之后，$P\left{|\frac{\sqrt{n}(\bar{x}-\mu)}{\sigma}| \leq u_{1-\frac{\alpha}{2}}\right}=1-\alpha$</p>
</blockquote>
<ul>
<li>方差未知区间估计</li>
</ul>
<blockquote>
<p>总体 $X \sim N\left(\mu, \sigma^{2}\right), \sigma^{2}$ 末知</p>
<ol>
<li>求参数 $\mu$ 的 $1-\alpha$ 置信区间</li>
</ol>
<p>$\bar{x} \sim N\left(\mu, \frac{\sigma^{2}}{n}\right), \quad \frac{\bar{x}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)$</p>
<p>$\bar{x}$ 与 $s^{2}$ 相互独立, 且 $\frac{(n-1) \cdot s^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)$，$\frac{\frac{\bar{x}-\mu}{\sigma / \sqrt{n}}}{\sqrt{\frac{(n-1) \cdot s^{2}}{\sigma^{2}}}}$ 可以将 $\sigma$ 的影响消去。</p>
<script type="math/tex; mode=display">
\frac{\frac{\bar{x}-\mu}{\sigma / \sqrt{n}}}{\sqrt{\frac{(n-1)s^2}{\sigma^2} /(n-1)}}=\frac{\bar{x}-\mu}{s / \sqrt{n}}=\frac{\sqrt{n}(\bar{x}-\mu)}{s} \sim t(n-1)</script><p>形式上是非常好记下来的。</p>
<p>$-t<em>{1-\frac{\alpha}{2}}(n-1) \leq \frac{\sqrt{n}(\bar{x}-\mu)}{s} \leq t</em>{1-\frac{\alpha}{2}}(n-1)$</p>
<p>$\bar{x}-\frac{s}{\sqrt{n}} t<em>{1-\frac{\alpha}{2}}(n-1) \leq \mu \leq \bar{x}+\frac{s}{\sqrt{n}} t</em>{1-\frac{\alpha}{2}}(n-1)$</p>
<ol>
<li>求 $\sigma^{2}$ 的 $1-\alpha$ 置信区间</li>
</ol>
<p>$\frac{(n-1) s^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)$ 可作为枢轴量，$\left(\chi<em>{\frac{\alpha}{2}}^{2} \leq \frac{(n-1) s^{2}}{\sigma^{2}} \leq \chi</em>{1-\frac{\alpha}{2}}^{2}\right)=1-\alpha$</p>
<script type="math/tex; mode=display">
P\left(\frac{(n-1) s^{2}}{\chi_{1-\frac{\alpha}{2}}^{2}} \leq \sigma^{2} \leq \frac{(n-1) s^{2}}{\chi_{\frac{\alpha}{2}}^{2}}\right)=1-\alpha \Rightarrow \sigma^{2} \in\left[\frac{(n-1) s^{2}}{\chi_{1-\frac{\alpha}{2}}^{2}}, \frac{(n-1) s^{2}}{\chi_{\frac{\alpha}{2}}^{2}}\right]</script><p><strong>去除未知参数的影响</strong></p>
</blockquote>
<ul>
<li>Behrens-Fisher 问题</li>
</ul>
<blockquote>
<p>$x<em>{1}, \cdots, x</em>{m}$ 来自正态总体 $N\left(\mu<em>{1}, \sigma</em>{1}{ }^{2}\right), y<em>{1}, \cdots, y</em>{n}$ 来自正态总体 $N\left(\mu<em>{2}, \sigma</em>{2}{ }^{2}\right), \mu<em>{1} 、 \mu</em>{2}$ 末知， $\sigma<em>{1}{ }^{2}=\sigma</em>{2}{ }^{2}=\sigma^2$ 末知，求 $\mu<em>{2}-\mu</em>{1}$ 的 $1-\alpha$ 置信区间。</p>
<p>$\bar{x} \sim N\left(\mu<em>{1}, \frac{\sigma^{2}}{m}\right), \bar{y} \sim N\left(\mu</em>{2}, \frac{\sigma^{2}}{n}\right), \quad \bar{x}-\bar{y} \sim N\left(\mu<em>{1}-\mu</em>{2}, \frac{\sigma^{2}}{m}+\frac{\sigma^{2}}{n}\right)$</p>
<p>$\frac{(m-1) s<em>{x}^{2}}{\sigma^{2}} \sim \chi^{2}(m-1), \frac{(n-1) s</em>{y}^{2}}{\sigma^{2}} \sim \chi^{2}(n-1), \quad \frac{(m-1) s<em>{x}^{2}}{\sigma^{2}}+\frac{(n-1) s</em>{y}^{2}}{\sigma^{2}} \sim \chi^{2}(m+n-2)$</p>
<script type="math/tex; mode=display">
\frac{\frac{(\bar{x}-\bar{y})-\left(\mu_{1}-\mu_{2}\right)}{\sigma \sqrt{\frac{1}{m}+\frac{1}{n}}}}{\sqrt{\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{\sigma^{2}} /(m+n-2)}}=\frac{\sqrt{m+n-2}}{\sqrt{\frac{1}{m}+\frac{1}{n}}} \cdot \frac{(\bar{x}-\bar{y})-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}} \sim t(m+n-2)</script><p><strong>这个问题还可以用渐进正态分布来处理</strong></p>
<p>$\frac{\bar{x}-\bar{y}-\left(\mu<em>{1}-\mu</em>{2}\right)}{\sqrt{\sigma<em>{x}^{2} / m+\sigma</em>{y}^{2} / n}} \sim N(0,1), \quad \frac{\bar{x}-\bar{y}-\left(\mu<em>{1}-\mu</em>{2}\right)}{\sqrt{s<em>{x}^{2} / m+s</em>{y}^{2} / n}} \sim N(0,1)$</p>
</blockquote>
<ul>
<li>正态方差之商的区间估计</li>
</ul>
<blockquote>
<p>例 $x<em>{1}, \cdots, x</em>{m}$ 来自正态总体 $N\left(\mu<em>{1}, \sigma</em>{1}^{2}\right), y<em>{1}, \cdots, y</em>{n}$ 来自正态总体 $N\left(\mu<em>{2}, \sigma</em>{2}{ }^{2}\right)$, $\mu<em>{1} 、 \mu</em>{2}$ 末知， $\sigma<em>{1}{ }^{2} 、 \sigma</em>{2}{ }^{2}$ 末知, 求 $\sigma<em>{1}{ }^{2} / \sigma</em>{2}{ }^{2}$ 的区间估计。</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\frac{(m-1) s_{1}{ }^{2}}{\sigma_{1}{ }^{2}} \sim \chi^{2}(m-1), \quad \frac{(n-1) s_{2}{ }^{2}}{\sigma_{2}{ }^{2}} \sim \chi^{2}(n-1) \\
\Rightarrow \quad F=\frac{s_{1}{ }^{2} / \sigma_{1}{ }^{2}}{s_{2}{ }^{2} / \sigma_{2}{ }^{2}} \sim F(m-1, n-1)
\end{array}</script></blockquote>
<ul>
<li>指数分布的区间分布</li>
</ul>
<blockquote>
<p>$x<em>{1}, \cdots, x</em>{n}$ 来自指数总体 $\operatorname{Exp}(\lambda)$, 求参数 $\lambda$ 的区间估计</p>
<p>可以证明 $X=2 \lambda\left(x<em>{1}+\cdots+x</em>{n}\right) \sim \chi^{2}(2 n) \Rightarrow 2 n \lambda \bar{x} \sim \chi^{2}(2 n)$</p>
<p>$P\left(\chi<em>{\frac{\alpha}{2}}^{2}(2 n) \leq 2 n \lambda \bar{x} \leq \chi</em>{1-\frac{\alpha}{2}}^{2}(2 n)\right)=1-\alpha$<br>$\Rightarrow \chi<em>{\frac{\alpha}{2}}^{2}(2 n) \leq 2 n \lambda \bar{x} \leq \chi</em>{1-\frac{\alpha}{2}}^{2}(2 n)$<br>$\Rightarrow \lambda \in\left[\chi<em>{\frac{\alpha}{2}}^{2}(2 n) / 2 n \bar{x}, \chi</em>{1-\frac{\alpha}{2}}^{2}(2 n) / 2 n \bar{x}\right]$</p>
</blockquote>
<ul>
<li>均匀分布的区间估计</li>
</ul>
<blockquote>
<p>$F<em>{x</em>{(j)}}(x, \theta)=\left(\frac{x}{\theta}\right)^{n}, \quad Y=\frac{x<em>{(n)}}{\theta}, \quad F</em>{Y}(y)=P(Y&lt;y)=P\left(\frac{x_{(n)}}{\theta}&lt;y\right)=y^{n}$</p>
<p>$\frac{x_{(n)}}{\theta}$ 可作为枢轴量</p>
<p>$P\left(c \leq \frac{x<em>{(n)}}{\theta} \leq d\right)=d^{n}-c^{n}=1-\alpha \Rightarrow \frac{x</em>{(n)}}{d} \leq \theta \leq \frac{x_{(n)}}{c}$</p>
<p>可取 $d=1, c=\sqrt[n]{\alpha}, \quad \theta \in\left[x<em>{(n)}, \frac{x</em>{(n)}}{\sqrt[n]{\alpha}}\right]$</p>
</blockquote>
<ul>
<li>基于渐进分布的两点分布区间估计</li>
</ul>
<blockquote>
<p>例 样本 $X<em>{1}, \cdots, X</em>{n}$ 来自两点分布总体 $\boldsymbol{b}(1, \boldsymbol{p})$, 求 $\boldsymbol{p}$ 的区间估计。<br>解：样本均值的期望、方差分别为 $E(\bar{X})=p, \operatorname{Var}(\bar{X})=\frac{p(1-p)}{n}$ 根据中心极限定理当 $n$ 较大时, 有近似分布 $\bar{X} \dot{\sim} N\left(p, \frac{p(1-p)}{n}\right)$, 标准化后得到枢轴量 $\frac{\bar{X}-p}{\sqrt{\frac{p(1-p)}{n}}} \dot{\sim} N(0,1)$</p>
<script type="math/tex; mode=display">
P\left(\left|\frac{\bar{X}-p}{\sqrt{p(1-p) / n}}\right| \leq u_{1 \frac{\alpha}{2}}\right) \approx 1-\alpha, \quad \text { 即 }(\bar{X}-p)^{2} \leq u_{1-\frac{\alpha}{2}}^{2} \frac{p(1-p)}{n}</script><p>$\frac{1}{1+c}\left(\bar{X}+\frac{c}{2}-\sqrt{\frac{\bar{X}(1-\bar{X})}{n} u<em>{1-\frac{\alpha}{2}}^{2}+\frac{c^{2}}{4}}\right) \leq p \leq \frac{1}{1+c}\left(\bar{X}+\frac{c}{2}+\sqrt{\frac{\bar{X}(1-\bar{X})}{n} u</em>{1-\frac{\alpha}{2}}^{2}+\frac{c^{2}}{4}}\right)$</p>
</blockquote>
<h1 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h1><ul>
<li>假设检验的基本步骤</li>
</ul>
<blockquote>
<ol>
<li>建立假设 $\mathrm{H}<em>{0}: \theta \in \Theta</em>{0} \quad$ VS $\quad H<em>{1}: \theta \in \Theta</em>{1}$（原假设和备择假设不一定是对立的）</li>
<li>选择检验统计量, 给出拒绝域的形式——所谓拒绝域 W是指使原假设被拒绝的样本观测值所在的区域, 有时也将 $\overline{\mathbf{W}}$ 称为接受域。</li>
<li>选择显著性水平 $\alpha$ (具体异常到什么程度拒绝原假设)。其定义为 $\alpha=\max \left{\mathrm{P}\left(\right.\right.$ 拒绝 $\mathrm{H}<em>{0} \mid \mathrm{H}</em>{0}$ 为真 $\left.)\right}=\max \left{\mathrm{P}<em>{\theta}(\mathrm{X} \in \mathbf{W}), \boldsymbol{\theta} \in \Theta</em>{0}\right}$，也即原假设成立时被拒绝的概率的最大值。（如果原假设是 $\mu \ge const$，那么 $\alpha$ 就是取最大值，一般就在 $\mu=const$ 时取到，如果原假设就是 $\mu=const$，那么 $\alpha$ 就是 $\mu=const$ 时被拒绝的概率）</li>
<li>给出拒绝域的具体范围。</li>
</ol>
</blockquote>
<ul>
<li>两类错误</li>
</ul>
<blockquote>
<p>第一类错误 $\alpha(\theta)=\mathrm{P}\left(\right.$ 拒绝 $\mathrm{H}<em>{0} \mid \mathrm{H}</em>{0}$ 为真 $)=\mathrm{P}<em>{\theta}(\mathrm{X} \in \mathrm{W}), \theta \in \Theta</em>{0}$</p>
<p>第二类错误 $\beta(\theta)=P\left(\right.$ 接受 $H<em>{0} \mid H</em>{1}$ 为真 $)=P<em>{\theta}(X \in \bar{W}), \theta \in \Theta</em>{1}$</p>
<p>举个例子：</p>
<p>对均匀总体 $U(0, \theta)$ 做假设检验, 原假设与备择假设分别为 $H<em>{0}: \theta=5, H</em>{1}: \theta&lt;5$, 以 $x<em>{(n)}=\max \left{x</em>{1}, \cdots, x_{n}\right}$ 为检验统计量, 显著性水平 $\alpha=0.064$, 若样本容量 $\boldsymbol{n}=\mathbf{3}$, 则拒绝域为</p>
<p>解: 只需要根据 $\alpha$ 的定义，原假设为真时，拒绝检验统计量的最大概率。</p>
<p>$P\left(x<em>{(n)}&lt;c\right)=\left(\frac{c}{5}\right)^{n}=\alpha \Rightarrow\left(\frac{c}{5}\right)^{3}=0.064 \Rightarrow c=2, \quad\left{\left(x</em>{1}, x<em>{2}, x</em>{3}\right): x_{(3)}&lt;2\right}$</p>
</blockquote>
<ul>
<li>U 检测（方差已知）</li>
</ul>
<blockquote>
<p>正态总体 $N\left(\mu, \sigma^{2}\right), \mu$ 末知, $\sigma^{2}$ 已知, 对 $\mu$ 做检验<br>检 验 统 计 量 $: u=\frac{\bar{x}-\mu<em>{0}}{\sigma / \sqrt{n}}=\frac{\sqrt{n}\left(\bar{x}-\mu</em>{0}\right)}{\sigma} \sim N(0,1)$ </p>
<p>$H<em>{0}: \mu=\mu</em>{0} ; \quad H<em>{1}: \mu \neq \mu</em>{0} \quad$ 拒绝域 $\bar{x}&gt;\mu<em>{0}+\frac{\sigma}{\sqrt{n}} u</em>{1-\frac{\alpha}{2}}$ 或 $\bar{x}&lt;\mu<em>{0}-\frac{\sigma}{\sqrt{n}} u</em>{1-\frac{\alpha}{2}}$</p>
<p> $H<em>{0}: \mu \geq \mu</em>{0} ; \quad H<em>{1}: \mu&lt;\mu</em>{0} \quad$ 拒绝域 $\bar{x}&lt;\mu<em>{0}-\frac{\sigma}{\sqrt{n}} u</em>{1-\alpha}$ </p>
<p>$H<em>{0}: \mu \leq \mu</em>{0} ; \quad H<em>{1}: \mu&gt;\mu</em>{0} \quad$ 拒绝域 $\bar{x}&gt;\mu<em>{0}+\frac{\sigma}{\sqrt{n}} u</em>{1-\alpha}$</p>
</blockquote>
<ul>
<li>t 检测（方差未知）</li>
</ul>
<blockquote>
<p>正态总体 $N\left(\mu, \sigma^{2}\right), \mu$ 末知, $\sigma^{2}$ 末知, 对 $\mu$ 做检验，检验统计量 $t=\frac{\bar{x}-\mu<em>{0}}{s / \sqrt{n}}=\frac{\sqrt{n}\left(\bar{x}-\mu</em>{0}\right)}{s} \sim t(n-1)$</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
H_{0}: \mu=\mu_{0} ; \quad H_{1}: \mu \neq \mu_{0} & \text { 拒绝域 } \bar{x}>\mu_{0}+\frac{\sigma}{\sqrt{n}} t_{1-\frac{\alpha}{2}}(n-1) \text { 或 } \bar{x}<\mu_{0}-\frac{\sigma}{\sqrt{n}} t_{1-\frac{\alpha}{2}}(n-1) \\
H_{0}: \mu \geq \mu_{0} ; H_{1}: \mu<\mu_{0} & \text { 拒绝域 } \bar{x}<\mu_{0}-\frac{\sigma}{\sqrt{n}} t_{1-\alpha}(n-1) \\
H_{0}: \mu \leq \mu_{0} ; H_{1}: \mu>\mu_{0} & \text { 拒绝域 } \bar{x}>\mu_{0}+\frac{\sigma}{\sqrt{n}} t_{1-\alpha}(n-1)
\end{array}</script></blockquote>
<ul>
<li>p 值（更异常的概率）</li>
</ul>
<blockquote>
<p>检验的 p 值: 在一个假设检验问题中, 利用样本观测值能够做出拒绝原假设的最小显著性水平; <strong>即原假设成立条件下, 检验统计量出现在比观测值更异常的范围的概率的最大值</strong></p>
<p>所谓更异常，指的是更偏向备择假设的那个方向。</p>
<p>判断产品是否优质的问题 $H<em>{0}: \mu \geq 10$ vs $H</em>{1}: \mu&lt;10$; 两次观测结果 $\bar{x}=9.3, \bar{x}=10.15$ </p>
<p>p 值分别为</p>
<script type="math/tex; mode=display">
\begin{array}{l}
p_{1}=P(\bar{x} \leq 9.3)=P\left(\frac{\bar{x}-10}{1 / 2} \leq \frac{9.3-10}{1 / 2}\right)=\Phi(-1.4)=0.081 \\
p_{2}=P(\bar{x} \leq 10.15)=P\left(\frac{\bar{x}-10}{1 / 2} \leq \frac{10.15-10}{1 / 2}\right)=\Phi(0.3)=0.618
\end{array}</script></blockquote>
<h1 id="拟合优度检验与贝叶斯估计"><a href="#拟合优度检验与贝叶斯估计" class="headerlink" title="拟合优度检验与贝叶斯估计"></a>拟合优度检验与贝叶斯估计</h1><ul>
<li>势函数</li>
</ul>
<blockquote>
<p>检验问题 $\mathrm{H}<em>{0}: \theta \in \Theta</em>{0} \quad\mathrm{ VS } \quad \mathrm{H}<em>{1}: \theta \in \Theta</em>{1}$ 拒绝域为 $\mathrm{X} \in \mathrm{W}$ 该检验的势函数: $\mathbf{g}(\theta)=P_{\theta}(X \in W)$</p>
<p>第一类错误 $\alpha(\theta)=\mathrm{P}\left(\right.$ 拒绝 $\mathrm{H}<em>{0} \mid \mathrm{H}</em>{0}$ 为真 $)=\mathrm{P}<em>{\theta}(\mathrm{X} \in \mathrm{W}), \theta \in \Theta</em>{0}$</p>
<p>第二类错误 $\beta(\theta)=P\left(\right.$ 接受 $H<em>{0} \mid H</em>{1}$ 为真 $)=P<em>{\theta}(X \in \bar{W}), \theta \in \Theta</em>{1}$</p>
<script type="math/tex; mode=display">
g(\theta)=\left\{\begin{array}{cc}
\alpha(\theta), & \theta \in \Theta_{0} \\
1-\beta(\theta), & \theta \in \Theta_{1}
\end{array}\right.</script><p>如果对任意的 $\theta \in \Theta_{0}$，都有 $\mathrm{g}(\theta) \leq \alpha$，则称该检验是显著性水平为 $\alpha$ 的显著性检验，简称显著性水平为 $\alpha$ 的检验或水平为 $\alpha$ 的检验</p>
</blockquote>
<ul>
<li>拟合优度检验</li>
</ul>
<blockquote>
<p>K.Pearson 的  $\chi^{2}$ 检验</p>
<p>设总体服从离散分布：</p>
<p>$\begin{array}{cccc}\boldsymbol{X} &amp; \boldsymbol{x}<em>{1} &amp; \cdots &amp; \boldsymbol{x}</em>{k} \ \boldsymbol{P} &amp; \boldsymbol{p}<em>{1} &amp; \cdots &amp; \boldsymbol{p}</em>{k}\end{array}$</p>
<p>进行 $n$ 次独立地观测, $k$ 个取值出现的频次分别为 $N<em>{i}(i=1, \cdots, k)$, 则 $X=\sum</em>{i=1}^{k} \frac{\left(N<em>{i}-n p</em>{i}\right)^{2}}{n p<em>{i}}$ 近似服从自由度为 $k-1$ 的 $\chi^{2}$ 分布。若需要通过样本估计 $\mathrm{s}$ 个参数，则 $X=\sum</em>{i=1}^{\mathrm{n}} \frac{\left(N<em>{i}-N p</em>{i}\right)^{2}}{N p_{i}}$ 近似服从自由度 $\mathrm{k}-\mathrm{s}-1$ 的卡方分布。</p>
</blockquote>
<ul>
<li>列联表检测</li>
</ul>
<blockquote>
<p>行 $c_i$，列 $d_i$</p>
<script type="math/tex; mode=display">
Y=\sum_{i=1}^{s} \sum_{j=1}^{t} \frac{\left(n_{i j}-n \cdot \frac{c_{i}}{n} \cdot \frac{d_{j}}{n}\right)^{2}}{n \cdot \frac{c_{i}}{n} \cdot \frac{d_{j}}{n}}=\sum_{i=1}^{s} \sum_{j=1}^{t} \frac{\left(n n_{i j}-c_{i} d_{j}\right)^{2}}{n c_{i} d_{j}}</script><p>近似服从自由度为 $(s-1)(t-1)$ 的 $\chi^{2}$ 分布</p>
</blockquote>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2022%E6%98%A5%E5%AD%A3/">2022春季</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-62b11572b25ab3ab" async="async"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/06/Lecture/2022%20Spring/deep_learning/"><img class="prev-cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Erik Mclean (FiTL2LuUcYY).jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Oscar Rodrigo Hernandez Panczenko (P0GQ95huhBo).jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Segement Me If U Can</div></div></a></div><div class="next-post pull-right"><a href="/2022/06/04/CS/%E7%A7%91%E7%A0%94/%E5%A4%A7%E4%BA%8C%E5%AD%A6%E5%B9%B4/Gau%20GAN/"><img class="next-cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Cassie Boca (gFyy2Po7T-k).jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Oscar Rodrigo Hernandez Panczenko (P0GQ95huhBo).jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Understanding Gau GAN</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/02/23/Lecture/2022%20Spring/probability/" title="Probability"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Dave Hoefler (yYABaqHw9WQ).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-23</div><div class="title">Probability</div></div></a></div><div><a href="/2022/04/02/Lecture/2022%20Spring/distribution/" title="Distribution Is All U Need"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Susan Q Yin (enx6829GjE0).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-02</div><div class="title">Distribution Is All U Need</div></div></a></div><div><a href="/2022/03/22/Lecture/2022%20Spring/Computer_graphics/" title="Computer Graphics"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Daniel Olah (2XyUPiXfEo0).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-22</div><div class="title">Computer Graphics</div></div></a></div><div><a href="/2022/05/25/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%94%E9%83%A8/" title="清华园日记——第五部"><img class="cover" src="https://zhaochenyang20.github.io/pic/embed/5_31_1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-25</div><div class="title">清华园日记——第五部</div></div></a></div><div><a href="/2022/05/17/Lecture/2022%20Spring/binaryDivdence/" title="深度学习基础"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by David Schultz (9kW2kO3q2i4).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-17</div><div class="title">深度学习基础</div></div></a></div><div><a href="/2022/03/15/Lecture/2022%20Spring/Introduction_to_AI/" title="Introduction to Artificial Intelligence"><img class="cover" src="https://pic.imgdb.cn/item/61eccb212ab3f51d91d5f245.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-15</div><div class="title">Introduction to Artificial Intelligence</div></div></a></div><div><a href="/2022/05/24/Lecture/2022%20Spring/Reinforcement/" title="重力四子棋"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Meckl Antal (dqaMpjwnvVA)(1).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-24</div><div class="title">重力四子棋</div></div></a></div><div><a href="/2022/06/06/Lecture/2022%20Spring/deep_learning/" title="Segement Me If U Can"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Erik Mclean (FiTL2LuUcYY).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-06</div><div class="title">Segement Me If U Can</div></div></a></div><div><a href="/2022/03/31/%E5%87%BA%E5%9B%BD/%E9%A1%B9%E8%84%8A%E8%BD%A9%E5%BF%97/" title="临别项脊轩"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Kym MacKinnon (JkLVPPwZtg8).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-31</div><div class="title">临别项脊轩</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#readme"><span class="toc-number">1.</span> <span class="toc-text">readme</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">2.</span> <span class="toc-text">统计学基本概念</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E7%82%B9%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%96%B9%E6%B3%95%E4%B8%8E%E8%AF%84%E4%BB%B7"><span class="toc-number">3.</span> <span class="toc-text">参数点估计的方法与评价</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1"><span class="toc-number">4.</span> <span class="toc-text">参数区间估计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C"><span class="toc-number">5.</span> <span class="toc-text">假设检验</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8B%9F%E5%90%88%E4%BC%98%E5%BA%A6%E6%A3%80%E9%AA%8C%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1"><span class="toc-number">6.</span> <span class="toc-text">拟合优度检验与贝叶斯估计</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background: ＃0096FF"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Eren Zhao</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><script type="text/javascript" id="maid-script" src="https://unpkg.com/mermaid@undefined/dist/mermaid.min.js?v=undefined"></script><script>if (window.mermaid) {
  var options = JSON.parse(document.getElementById('maid-script').getAttribute('mermaidoptioins'));
  mermaid.initialize(options);
}</script></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库正在艰难运行</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '978121c7b834efdd76be',
      clientSecret: '59b40e8f39a1c33db5a2c891771086164b9575c4',
      repo: 'zhaochenyang20.github.io',
      owner: 'zhaochenyang20',
      admin: ['zhaochenyang20'],
      id: 'f18f772ff0e92001bd127a2a9a541a6c',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/"});</script></body></html>