<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Statistics | 求道之人，不问寒暑</title><meta name="keywords" content="2022春季,数学"><meta name="author" content="Eren Zhao"><meta name="copyright" content="Eren Zhao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="梁老师教的蛮好，你把他 PF 了干嘛？">
<meta property="og:type" content="article">
<meta property="og:title" content="Statistics">
<meta property="og:url" content="http://example.com/2022/06/06/Lecture/2022%20Spring/statistic/index.html">
<meta property="og:site_name" content="求道之人，不问寒暑">
<meta property="og:description" content="梁老师教的蛮好，你把他 PF 了干嘛？">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by eberhard 🖐 grossgasteiger (mWuXdxtesG0).jpg">
<meta property="article:published_time" content="2022-06-06T06:31:12.104Z">
<meta property="article:modified_time" content="2022-08-26T16:20:11.687Z">
<meta property="article:author" content="Eren Zhao">
<meta property="article:tag" content="2022春季">
<meta property="article:tag" content="数学">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by eberhard 🖐 grossgasteiger (mWuXdxtesG0).jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://example.com/2022/06/06/Lecture/2022%20Spring/statistic/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"麻了，找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Statistics',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2022-08-27 00:20:11'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/mouse.css"><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="求道之人，不问寒暑" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}</style></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend.jpg'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">192</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">31</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/list-100/"><i class="fa-fw fas fa-music"></i><span> TODO</span></a></div><div class="menus_item"><a class="site-page" href="/projects/"><i class="fa-fw fas fa-video"></i><span> Projects</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by eberhard 🖐 grossgasteiger (mWuXdxtesG0).jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">求道之人，不问寒暑</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/list-100/"><i class="fa-fw fas fa-music"></i><span> TODO</span></a></div><div class="menus_item"><a class="site-page" href="/projects/"><i class="fa-fw fas fa-video"></i><span> Projects</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Statistics</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-06-06T06:31:12.104Z" title="发表于 2022-06-06 14:31:12">2022-06-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-26T16:20:11.687Z" title="更新于 2022-08-27 00:20:11">2022-08-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B/">课程</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B/%E6%A6%82%E7%BB%9F/">概统</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>30分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Statistics"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="readme">readme</h1>
<ul>
<li>梁衡老师的概统讲的很好，<del>少数我想线下听的课</del>，可惜也没好好听，而且记了
PF，就当复习个快乐，学习没那么 targeted</li>
<li>我总结下每一章比较有意思的地方，这一部分是统计</li>
</ul>
<h1 id="统计学基本概念">统计学基本概念</h1>
<ul>
<li>样本均值</li>
</ul>
<blockquote>
<p>设 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span>
是来自某个总体的样本, <span class="math inline">\(\bar{x}\)</span>
为样本均值,</p>
<ol type="1">
<li>若总体分布为 <span class="math inline">\(N\left(\mu,
\sigma^{2}\right)\)</span>, 则 <span class="math inline">\(\bar{x} \sim
N\left(\mu, \frac{\sigma^{2}}{n}\right)\)</span>;</li>
<li>若总体分布不是正态分布或根本末知, <span
class="math inline">\(E(X)=\mu,
\operatorname{Var}(X)=\sigma^{2}\)</span>, 则 <span
class="math inline">\(n\)</span> 较大时, <span
class="math inline">\(\bar{x}\)</span> 的渐近分布为 <span
class="math inline">\(N\left(\mu, \frac{\sigma^{2}}{n}\right)\)</span>,
常记为 <span class="math inline">\(\bar{x} \dot{\sim} N\left(\mu,
\frac{\sigma^{2}}{n}\right)\)</span> (中心极限定理）</li>
<li>实际上，如果 X 的分布本身不是正态分布，则 $ E({x})=,Var({x})= $
仍然成立，只是不严格正态。而 n 足够大的时候，渐进为正态分布</li>
</ol>
</blockquote>
<ul>
<li>样本方差</li>
</ul>
<blockquote>
<p>样木本方差 <span class="math inline">\(s^{2}=\frac{1}{n-1}
\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\)</span></p>
<p>设总体 <span class="math inline">\(X\)</span> 具有二阶矩, 即 <span
class="math inline">\(E(X)=\mu,
\operatorname{Var}(X)=\sigma^{2}&lt;+\infty\)</span>, <span
class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span>
为从该总体得到的样本, <span class="math inline">\(\bar{x}\)</span> 和
<span class="math inline">\(s^{2}\)</span> 分别是样本均值和样本方差, 则
<span class="math inline">\(E(\bar{x})=\mu,
\operatorname{Var}(\bar{x})=\frac{\sigma^{2}}{n},
E\left(s^{2}\right)=\sigma^{2}\)</span> （无偏估计）</p>
<blockquote>
<p>注意，<span class="math inline">\(s^2\)</span> 是 <span
class="math inline">\(\sigma^2\)</span> 的无偏估计，但是并不意味着 <span
class="math inline">\(s\)</span> 是 <span
class="math inline">\(\sigma\)</span> 的无偏估计</p>
<p>Var <span
class="math inline">\((S)=E\left(S^{2}\right)-E(S)^{2}=\sigma^{2}-E(S)^{2}&gt;0\)</span>,
所以 <span class="math inline">\(E(S)&lt;\sigma\)</span></p>
</blockquote>
<p><span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span>
是来自均匀总体 <span class="math inline">\(X \sim U(-a, a)\)</span>
的样本, 用矩估计法估计参数 <span class="math inline">\(a\)</span>。</p>
<p><span
class="math inline">\(\operatorname{Var}(X)=\frac{a^{2}}{3}\)</span>, 令
<span class="math inline">\(\frac{a^{2}}{3}=s^{2} \Rightarrow
\hat{a}=\sqrt{3} s\)</span>，但不是无偏估计。</p>
<p>样本 <span class="math inline">\(k\)</span> 阶原点矩 <span
class="math inline">\(a_{k}=\frac{1}{n} \sum_{i=1}^{n}
x_{i}^{k}\)</span>, 样本 <span class="math inline">\(k\)</span> 阶中心矩
<span class="math inline">\(b_{k}=\frac{1}{n}
\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{k}\)</span></p>
</blockquote>
<ul>
<li>次序统计量</li>
</ul>
<blockquote>
<p>对于次序统计量，利用习题课 1 上的 trick 即可</p>
</blockquote>
<ul>
<li>三大分布</li>
</ul>
<blockquote>
<ol type="1">
<li><span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span>
独立同分布, 服从 <span class="math inline">\(N(0,1)\)</span> 则 <span
class="math inline">\(Y=X_{1}{ }^{2}+\cdots+X_{n}{ }^{2} \sim \chi_{n}{
}^{2}\)</span> 或 <span class="math inline">\(\chi^{2}(n)\)</span>,
称为自由度为 <span class="math inline">\(n\)</span> 的 <span
class="math inline">\(\chi^{2}\)</span> 分布 —— <span
class="math inline">\(n\)</span> 个独立同分布的标准正态分布之和为 <span
class="math inline">\(n\)</span> 自由度的卡方分布</li>
<li><span class="math inline">\(t\)</span> 分布 <span
class="math inline">\(X_{1} \sim N(0,1), X_{2} \sim \chi_{n}^{2}, X_{1},
X_{2}\)</span> 相互独立 <span
class="math inline">\(t=\frac{X_{1}}{\sqrt{X_{2} / n}} \sim
t(n)\)</span>, 称为自由度为 <span class="math inline">\(n\)</span> 的
<span class="math inline">\(t\)</span> 分布 —— 标准正态分布除以独立的
<span class="math inline">\(n\)</span> 自由度卡方分布除 <span
class="math inline">\(n\)</span> 开根为 <span
class="math inline">\(n\)</span> 自由度的 <span
class="math inline">\(t\)</span> 分布</li>
<li><span class="math inline">\(F\)</span> 分布 <span
class="math inline">\(X_{1}, X_{2}\)</span> 相互独立, <span
class="math inline">\(X_{1} \sim \chi_{m}{ }^{2}, X_{2} \sim \chi_{n}{
}^{2},F=\frac{X_{1} / m}{X_{2} / n} \sim F(m, n)\)</span> 称为自由度为
<span class="math inline">\(m\)</span> 与 <span
class="math inline">\(n\)</span> 的 <span
class="math inline">\(F\)</span> 分布</li>
</ol>
</blockquote>
<blockquote>
<p>举个例子，构造分布：</p>
<p>设 <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{8}\)</span>
为相互独立的 <span class="math inline">\(N(0,1)\)</span> 随机变量, 则
<span
class="math inline">\(P\left(\frac{X_{1}-X_{2}}{\left|X_{1}+X_{2}+\cdots+X_{8}\right|}
\geq ?\right)= 0.05\)</span></p>
<p>解: <span class="math inline">\(X_{1}-X_{2} \sim N(0,2), \quad
X_{1}+X_{2}+\ldots+X_{8} \sim N(0,8)\)</span></p>
<p><span class="math inline">\(\operatorname{Cov}\left(X_{1}-X_{2},
X_{1}+X_{2}\right)=0\)</span></p>
<p>构造 F 分布：</p>
<p><span class="math inline">\(\frac{\left(X_{1}-X_{2}\right)^{2} /
2}{\left(X_{1}+X_{2}+\ldots+X_{8}\right)^{2} / 8} \sim F(1,1), \quad
P\left(\frac{\left(X_{1}-X_{2}\right)^{2} /
2}{\left(X_{1}+X_{2}+\ldots+X_{8}\right)^{2} / 8} \geq
F_{0.9}(1,1)\right)=0.1\)</span></p>
<p><span class="math inline">\(P\left(\frac{\left(X_{1}-X_{2}\right) /
\sqrt{2}}{\left|X_{1}+X_{2}+X_{3}+X_{4}\right| / 2 \sqrt{2}} \geq
\sqrt{F_{0.9}(1,1)}\right)=0.05 \Rightarrow
P\left(\frac{X_{1}-X_{2}}{\left|X_{1}+X_{2}+X_{3}+X_{4}\right|} \geq
\frac{\sqrt{F_{0.9}(1,1)}}{2}\right)=0.05\)</span></p>
<p><span
class="math inline">\(P\left(\frac{X_{1}-X_{2}}{\left|X_{1}+X_{2}+X_{3}+X_{4}\right|}
\geq \sqrt{10}\right)=0.05\)</span></p>
<p>构造 T 分布：</p>
<p><span class="math inline">\(\frac{\left(X_{1}-X_{2}\right) /
\sqrt{2}}{\sqrt{\left(X_{1}+X_{2}+\ldots+X_{8}\right)^{2} / 8}} \sim
t(1), \quad P\left(\frac{\left(X_{1}-X_{2}\right) /
\sqrt{2}}{\left|X_{1}+X_{2}+\ldots+X_{8}\right| / \sqrt{8}} \geq
t_{0.95}(1)\right)=0.05\)</span></p>
<p><span
class="math inline">\(P\left(\frac{X_{1}-X_{2}}{\left|X_{1}+X_{2}+X_{3}+X_{4}\right|}
\geq \frac{t_{0.95}(1)}{2}\right)=0.05, \quad
P\left(\frac{X_{1}-X_{2}}{\left|X_{1}+X_{2}+X_{3}+X_{4}\right|} \geq
3.16\right)=0.05\)</span></p>
</blockquote>
<ul>
<li>分布反演</li>
</ul>
<blockquote>
<p>设随机变量 <span class="math inline">\(\xi\)</span> 服从自由度为
<span class="math inline">\((1,1)\)</span> 的 <span
class="math inline">\(F\)</span> 分布, 则 <span
class="math inline">\(P(\xi \leq 1)=(\quad)\)</span></p>
<p>设 <span class="math inline">\(X_{1} \sim \chi^{2}(1), X_{2} \sim
\chi^{2}(1), X_{1} 、 X_{2}\)</span> 相互独立, 所以</p>
<p><span class="math inline">\(P\left(X_{1} \leq
X_{2}\right)=P\left(X_{1} \geq X_{2}\right)=\frac{1}{2}, \quad P(\xi
\leq 1)=P\left(\frac{X_{1}}{X_{2}} \leq 1\right)=P\left(X_{1} \leq
X_{2}\right)=\frac{1}{2}\)</span></p>
<hr />
<p>设随机变量 <span class="math inline">\(T\)</span> 服从自由度为 1 的
<span class="math inline">\(t\)</span> 分布, 则 <span
class="math inline">\(P(T \leq 1)=(\quad)\)</span></p>
<p>设 <span class="math inline">\(X, Y\)</span> 相互独立, 且均服从 <span
class="math inline">\(N(0,1)\)</span>, 则 <span
class="math inline">\(\frac{X}{|Y|}\)</span> 服从自由度为 1 的 <span
class="math inline">\(t\)</span> 分布, 于是</p>
<p><span class="math inline">\(\begin{array}{l} P(T \leq 1)=P(T \leq
0)+P(0&lt;T&lt;1)=0.5+\frac{1}{2} P(|T|&lt;1) \\ =0.5+0.5 \times
P\left(X^{2}&lt;Y^{2}\right)=0.5+0.5 \times 0.5=0.75
\end{array}\)</span></p>
<blockquote>
<p>这个稍微需要理解下，<span class="math inline">\(X\)</span>
为负数时，<span class="math inline">\(T\)</span> 必小于 0，此即 <span
class="math inline">\(P(T\le0)=\frac{1}{2}\)</span>。而 <span
class="math inline">\(P(0\le T\le 1)=P(X\ge 0)\times p(X\le
|Y|)=\frac{1}{2}\times P(X^2\le Y^2)=\frac{1}{4}\)</span></p>
<p>还有一个想法，<span class="math inline">\(P(X\le |Y|\)</span>
按照全概率公式，分为 <span class="math inline">\(P(Y\le 0) \times P(X\le
-Y|Y \le 0)+P(Y\ge 0)\times P(X\le Y|Y \ge
0)\)</span>，这个方法很简单，重点是不要忘了全概率公式应该乘的是条件概率。</p>
</blockquote>
</blockquote>
<h1 id="参数点估计的方法与评价">参数点估计的方法与评价</h1>
<ul>
<li>矩估计</li>
</ul>
<blockquote>
<p>尽量用低阶矩来估计参数</p>
</blockquote>
<ul>
<li><a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26614750">极大似然估计</a></li>
</ul>
<blockquote>
<p>对于二元函数 <span class="math inline">\(p(x ,\theta)\)</span>
输入有两个：<span class="math inline">\(\mathrm{x}\)</span>
表示某一个具体的数据，<span class="math inline">\(\theta\)</span>
表示模型的参数</p>
<p>如果 <span class="math inline">\(\theta\)</span> 是已知确定的，<span
class="math inline">\(x\)</span> 是变量, 即为概率函数(probability
function)，它描述对于不同样本点 <span class="math inline">\(x\)</span>,
其出现概率是多少</p>
<p>如果 <span class="math inline">\(x\)</span> 是已知确定的，<span
class="math inline">\(\theta\)</span>
是变量，这个函数叫做似然函数(likelihood
function)，它描述对于不同的模型参数，出现 <span
class="math inline">\(x\)</span> 这个样本点的概率是多少</p>
<p><strong>我们想办法让观察样本出现的概率最大</strong>，就是极大似然估计</p>
</blockquote>
<ul>
<li>对数似然函数</li>
</ul>
<blockquote>
<p><span class="math inline">\(\ln (L(\theta))\)</span>，由于 <span
class="math inline">\(\ln x\)</span> 是 <span
class="math inline">\(x\)</span> 的单调函数，使得 <span
class="math inline">\(\ln (L(\theta))\)</span> 与 <span
class="math inline">\(L(\theta)\)</span> 达到最大的 <span
class="math inline">\(\theta\)</span>
相同，常利用对数似然函数求解极大似然估计。</p>
</blockquote>
<ul>
<li>泊松分布与全损指数分布的极大似然估计</li>
</ul>
<blockquote>
<p><span
class="math inline">\(\hat{\lambda_{Poisson}}=\overline{\boldsymbol{x}}\)</span>，<span
class="math inline">\(\hat{\lambda_{Exponential}}=\frac{1}{\bar{x}}\)</span></p>
</blockquote>
<ul>
<li>有损指数分布的极大似然估计</li>
</ul>
<blockquote>
<p>设寿命小于 <span class="math inline">\(T\)</span> 的 <span
class="math inline">\(r\)</span> 个观测值为 <span
class="math inline">\(x_{1}, x_{2}, \cdots, x_{r}\)</span>, 对应的 <span
class="math inline">\(r\)</span> 个 <span
class="math inline">\(y_{k}\)</span> 的值</p>
<p>剩下的 <span class="math inline">\(n-r\)</span> 个 <span
class="math inline">\(y_{k}\)</span> 的取值均为 <span
class="math inline">\(T\)</span>, 每一个发生概率为 <span
class="math inline">\(P(X \geq T)=e^{-\lambda T}\)</span></p>
<p>似然函数 <span class="math inline">\(L\left(\lambda ; y_{1}, y_{2},
\cdots, y_{n}\right)=\lambda^{r}
e^{-\lambda\left(x_{1}+x_{2}+\cdots+x_{r}\right)} \cdot e^{-\lambda(n-r)
T}\)</span></p>
<p><span class="math inline">\(\ln L(\lambda)=r \ln
\lambda-\lambda\left(x_{1}+x_{2}+\cdots+x_{r}\right)-\lambda(n-r)
T\)</span></p>
<p><span class="math inline">\(\begin{array}{l} \frac{d \ln
L(\lambda)}{d
\lambda}=\frac{r}{\lambda}-\left(x_{1}+x_{2}+\cdots+x_{r}+(n-r)
T\right)=0 \\ \Rightarrow \hat{\lambda}=r
/\left[x_{1}+\cdots+x_{r}+(n-r) T\right] \end{array}\)</span></p>
</blockquote>
<ul>
<li>均匀分布的极大似然估计</li>
</ul>
<blockquote>
<p>参数 <span class="math inline">\(a, b\)</span> 的极大似然估计 <span
class="math inline">\(\hat{a}=\min \left(\boldsymbol{X}_{1},
\boldsymbol{X}_{2} \cdots, \boldsymbol{X}_{n}\right), \hat{b}=\max
\left(\boldsymbol{X}_{1}, \boldsymbol{X}_{2} \cdots,
\boldsymbol{X}_{n}\right)\)</span></p>
<p><strong>极大似然估计得到的不一定是无偏估计</strong></p>
</blockquote>
<ul>
<li>柯西分布的极大似然估计</li>
</ul>
<blockquote>
<p>Cauchy 分布随机变量的期望不存在, 因此不能用矩估计法对参数 <span
class="math inline">\(\theta\)</span> 进行估计</p>
<p>设 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span>
为来自该总体的样本观测值</p>
<p>似然函数 <span class="math inline">\(L(\theta)=\prod_{k=1}^{n}
f\left(x_{k} ; \theta\right)=\prod_{k=1}^{n}
\frac{1}{\pi\left[1+\left(x_{k}-\theta\right)^{2}\right]}\)</span></p>
<p>对数似然函数 <span class="math inline">\(\ln
L(\theta)=\sum_{k=1}^{n}-\left(\ln \pi+\ln
\left(1+\left(x_{k}-\theta\right)^{2}\right)\right)\)</span></p>
<p>将上式对 <span class="math inline">\(\theta\)</span> 求导，并令其等于
0</p>
<p><span class="math inline">\(\frac{d \ln L(\theta)}{d
\theta}=-\sum_{k=1}^{n}
\frac{x_{k}-\theta}{1+\left(x_{k}-\theta\right)^{2}}=0\)</span></p>
<p>方程无法的到解析解，需要用一定的计算方法近似求解</p>
</blockquote>
<ul>
<li>相合估计</li>
</ul>
<blockquote>
<p>定理: 设 <span
class="math inline">\(\hat{\theta}_{n}=\hat{\theta}_{n}\left(x_{1},
x_{2}, \cdots, x_{n}\right)\)</span> 是 <span
class="math inline">\(\theta\)</span> 的一个估计量, 若 <span
class="math inline">\(\lim _{n \rightarrow \infty}
E\left(\hat{\theta}_{n}\right)=\theta \quad \lim _{n \rightarrow \infty}
\operatorname{Var}\left(\hat{\theta}_{n}\right)=0\)</span>，则 <span
class="math inline">\(\hat{\theta}_{n}\)</span> 是参数 <span
class="math inline">\(\theta\)</span> 的相合估计。</p>
</blockquote>
<ul>
<li>无偏性与有效性</li>
</ul>
<blockquote>
<p>无偏性，保证没有系统偏差</p>
<p>设 <span class="math inline">\(\theta \in \Theta\)</span> 为末知参数,
<span class="math inline">\(\hat{\theta}=\hat{\theta}\left(x_{1}, x_{2},
\cdots, x_{n}\right)\)</span> 是 <span
class="math inline">\(\theta\)</span> 的一个估计量，若对任意 <span
class="math inline">\(\theta \in \Theta\)</span> 有 <span
class="math inline">\(E(\hat{\theta})=\theta\)</span>，则称 <span
class="math inline">\(\hat{\theta}\)</span> 是参数 <span
class="math inline">\(\theta\)</span> 的无偏估计。</p>
<p>有效性，希望估计围绕参数波动的幅度越小越好。</p>
<p>设 <span class="math inline">\(\hat{\theta}_{1},
\hat{\theta}_{2}\)</span> 是参数 <span
class="math inline">\(\theta\)</span> 的无偏估计，如果对任意 <span
class="math inline">\(\theta \in \Theta\)</span> 有 <span
class="math inline">\(\operatorname{Var}\left(\hat{\theta}_{1}\right)
\leq
\operatorname{Var}\left(\hat{\theta}_{2}\right)\)</span>，且至少有一个
<span class="math inline">\(\theta \in \Theta\)</span>
使得上述不等号严格成立，则称 <span
class="math inline">\(\hat{\theta}_{1}\)</span> 比 <span
class="math inline">\(\hat{\theta}_{2}\)</span> 有效。</p>
<p>简单的应用：样本数量的增加会改善估计。</p>
</blockquote>
<ul>
<li><strong>极大似然估计</strong>得到的不一定是无偏估计</li>
</ul>
<blockquote>
<p><span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span>
是来自均匀总体 <span class="math inline">\(U(0, \theta)\)</span>
的样本，参数 <span class="math inline">\(\theta\)</span>
的极大似然估计量 <span class="math inline">\(\tilde{\theta}=\max _{1
\leq k \leq n} X_{k}\)</span>, 考查无偏性。</p>
<p>计算 <span class="math inline">\(\tilde{\theta}=\max _{1 \leq k \leq
n} X_{k}\)</span> 的分布函数，当 <span class="math inline">\(0 \leq y
\leq \theta\)</span> 时, 由样本的独立同分布性质，可知其分布函数（CDF）为
<span class="math display">\[
F_{\dot{\theta}}(y)=P(\tilde{\theta} \leq y)=P\left(\max _{1 \leq k \leq
n} X_{k} \leq y\right)=\prod_{k=1}^{n} P\left(X_{k} \leq
y\right)=\left(\frac{y}{\theta}\right)^{n}
\]</span> <span class="math inline">\(\tilde{\theta}=\max _{1 \leq k
\leq n} X_{k}\)</span> 的分布函数 <span
class="math inline">\(F_{\tilde{\theta}}(y)=\left\{\begin{array}{c}0,
y&lt;0 \\ \left(\frac{y}{\theta}\right)^{n}, 0 \leq y \leq \theta, \\ 1,
y&gt;\theta\end{array}\right.\)</span> 于是 <span
class="math inline">\(\tilde{\theta}\)</span> 的概率密度（PDF）为 <span
class="math inline">\(f_{\tilde{\theta}}(y)=\left\{\begin{array}{c}\frac{n}{\theta^{n}}
y^{n-1}, y \in[0, \theta] \\ 0, \text { 其它 }\end{array}
\quad\right.\)</span> 因此, 我们有 <span class="math display">\[
\begin{aligned}
E(\tilde{\theta}) &amp;=\int_{-\infty}^{+\infty} y f_{\tilde{\theta}}(y)
d y=\int_{0}^{\theta} y \frac{n}{\theta^{n}} y^{n-1} d y \\
&amp;=\frac{n}{\theta^{n}} \int_{0}^{\theta} y^{n} d
y=\left.\frac{n}{\theta^{n}} \cdot \frac{y^{n+1}}{n+1}\right|_{0}
^{\theta}=\frac{n}{n+1} \theta
\end{aligned}
\]</span> <span class="math inline">\(E(\tilde{\theta})=E\left(\max _{1
\leq k \leq n} X_{k}\right)=\frac{n}{n+1} \theta\)</span>，统计量 <span
class="math inline">\(\max _{1 \leq k \leq n} X_{k}\)</span> 不是参数
<span class="math inline">\(\theta\)</span> 的无偏估计，<span
class="math inline">\(\frac{n+1}{n} \max _{1 \leq k \leq n}
X_{k}\)</span> 则为无偏估计，称为无偏校正。</p>
</blockquote>
<ul>
<li>正态分布的极大似然估计</li>
</ul>
<blockquote>
<p>所以参数 <span class="math inline">\(\mu\)</span> 和 <span
class="math inline">\(\sigma^{2}\)</span> 的极大似然估计量为 <span
class="math inline">\(\hat{\mu}=\bar{X}, \hat{\sigma}^{2}=\frac{1}{n}
\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\)</span>（与 <span
class="math inline">\(s^{2}=\frac{1}{n-1}
\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\)</span> 完全没关系，而
<span class="math inline">\(s^2\)</span> 是 <span
class="math inline">\(\sigma^2\)</span> 的无偏估计）</p>
<p>注意，估计的不是 <span class="math inline">\(\sigma\)</span>，而是
<span class="math inline">\(\sigma^2\)</span></p>
</blockquote>
<ul>
<li>均方误差</li>
</ul>
<blockquote>
<p><span class="math display">\[
\begin{aligned}
\operatorname{MSE}(\hat{\theta})=E(\hat{\theta}-\theta)^{2}
&amp;=E[(\hat{\theta}-E(\hat{\theta}))+(E(\hat{\theta})-\theta)]^{2} \\
&amp;=\operatorname{Var}(\hat{\theta})+(\boldsymbol{E}(\hat{\theta})-\theta)^{2}
\end{aligned}
\]</span> 若 <span class="math inline">\(\hat{\theta}\)</span> 是参数
<span class="math inline">\(\theta\)</span> 的无偏估计, 则 <span
class="math inline">\(\operatorname{MSE}(\hat{\theta})=\operatorname{Var}(\hat{\theta})\)</span></p>
<p>注: 很多时候, 无偏估计的均方误差会小于有偏估计的均方误差,
但二者之间并没有严格的对应关系，例如书上 324 页（第三版 286-287 页）例
6.4.1 即给出一个有偏估计均方误差小于无偏估计均方误差的实例。</p>
</blockquote>
<h1 id="参数区间估计">参数区间估计</h1>
<ul>
<li>置信系数</li>
</ul>
<blockquote>
<p>抽取 n 个样本得到一个区间估计, 将这样的估计重复足够多次, 至少 <span
class="math inline">\(1-\alpha\)</span> 比例的估计区间包含真实的 <span
class="math inline">\(\mu\)</span> 值。这里置信系数是 <span
class="math inline">\(0.9544\)</span>, 即大约 <span
class="math inline">\(95.44 \%\)</span> 估计区间包含真实的 <span
class="math inline">\(\mu\)</span> 值。</p>
<p>或者说，这种抽样方法得到的这些区间至少有 <span
class="math inline">\(1-\alpha\)</span> 的概率包含真实的 <span
class="math inline">\(\mu\)</span> 值。</p>
<p>末知参数本身是确定的值, 不带有随机性。随机性是由区间引入的。</p>
</blockquote>
<ul>
<li>下侧 <span class="math inline">\(\alpha\)</span> 分位数</li>
</ul>
<blockquote>
<p><span class="math inline">\(\Phi(d)=1-\frac{\alpha}{2}, \quad
F(c)=\frac{\alpha}{2} \quad \Rightarrow \quad
d=\Phi^{-1}\left(1-\frac{\alpha}{2}\right), \quad
c=\Phi^{-1}\left(\frac{\alpha}{2}\right)\)</span></p>
<p>标准正态分布的 <span
class="math inline">\(1-\frac{\alpha}{2}\)</span> 分位数和 <span
class="math inline">\(\frac{\alpha}{2}\)</span> 分位数，<span
class="math inline">\(d=u_{1-\frac{\alpha}{2}}, \quad
c=u_{\frac{\alpha}{2}}=-u_{1-\frac{\alpha}{2}}\)</span></p>
<p>在此基础上，可以看出 <span
class="math inline">\(P(u_{\frac{\alpha}{2}}\le Z\le
u_{1-\frac{\alpha}{2}})=P(|Z|\le
u_{1-\frac{\alpha}{2}})，u_{\alpha}=-u_{1-\alpha}\)</span></p>
<p>最主要的还是理解分位数的反函数定义，小于 <span
class="math inline">\(\alpha\)</span> 分位点的概率是 <span
class="math inline">\(\alpha\)</span></p>
</blockquote>
<blockquote>
<p>标准正态分布的 <span class="math inline">\(\alpha\)</span> 分位点记为
<span class="math inline">\(u_{\alpha}\)</span></p>
<p><span class="math inline">\(n\)</span> 个自由度的 <span
class="math inline">\(\chi^{2}\)</span> 分布的 <span
class="math inline">\(\alpha\)</span> 分位点记为 <span
class="math inline">\(\chi_{\alpha}^{2}(n)\)</span></p>
<p><span class="math inline">\(n\)</span> 个自由度的 <span
class="math inline">\(t\)</span> 分布的 <span
class="math inline">\(\alpha\)</span> 分位点记为 <span
class="math inline">\(t_{\alpha}(n)\)</span></p>
<p><span class="math inline">\((m, n)\)</span> 自由度的 <span
class="math inline">\(F\)</span> 分布的 <span
class="math inline">\(\alpha\)</span> 分位点记为 <span
class="math inline">\(F_{\alpha}(m, n)\)</span></p>
<p><span class="math inline">\(X\)</span> 为一连续分布随机变量, 如果
<span class="math inline">\(P(X \geq a)=\alpha\)</span>, <span
class="math inline">\(a\)</span> 称为上侧 <span
class="math inline">\(\alpha\)</span> 分位数</p>
</blockquote>
<ul>
<li>统计抽样定理</li>
</ul>
<blockquote>
<p>设 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span>
是来自正态总体 <span class="math inline">\(N\left(\mu,
\sigma^{2}\right)\)</span> 的样本, 其样本均值和样本方差分别为: <span
class="math inline">\(\bar{x}=\frac{x_{1}+x_{2}+\cdots+x_{n}}{n}\)</span>
和 <span class="math inline">\(s^{2}=\frac{1}{n-1}
\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\)</span>, 则有</p>
<ol type="1">
<li><span class="math inline">\(\bar{x}\)</span> 与 <span
class="math inline">\(s^{2}\)</span> 相互独立</li>
<li><span class="math inline">\(\bar{x} \sim N\left(\mu,
\frac{\sigma^{2}}{n}\right)\)</span></li>
<li><span class="math inline">\(\frac{(n-1) \cdot s^{2}}{\sigma^{2}}
\sim \chi^{2}(n-1)\)</span></li>
</ol>
</blockquote>
<ul>
<li>方差已知区间估计</li>
</ul>
<blockquote>
<p>总体 <span class="math inline">\(N\left(\mu, \sigma^{2}\right),
\sigma^{2}\)</span> 已知，<span class="math inline">\(\mu\)</span>
末知，<span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span>
是简单随机样本, 求 <span class="math inline">\(\mu\)</span> 的1- <span
class="math inline">\(\alpha\)</span> 置信区间</p>
<p><span
class="math inline">\(\frac{\bar{x}-\mu}{\sqrt{\frac{\sigma^{2}}{n}}}\)</span>
可作为枢轴量, <span
class="math inline">\(Z=\frac{\bar{x}-\mu}{\sqrt{\frac{\sigma^{2}}{n}}}=\frac{\sqrt{n}(\bar{x}-\mu)}{\sigma}
\sim N(0,1)\)</span></p>
<p>构造出枢轴量之后，<span
class="math inline">\(P\left\{|\frac{\sqrt{n}(\bar{x}-\mu)}{\sigma}|
\leq u_{1-\frac{\alpha}{2}}\right\}=1-\alpha\)</span></p>
</blockquote>
<ul>
<li>方差未知区间估计</li>
</ul>
<blockquote>
<p>总体 <span class="math inline">\(X \sim N\left(\mu,
\sigma^{2}\right), \sigma^{2}\)</span> 末知</p>
<ol type="1">
<li>求参数 <span class="math inline">\(\mu\)</span> 的 <span
class="math inline">\(1-\alpha\)</span> 置信区间</li>
</ol>
<p><span class="math inline">\(\bar{x} \sim N\left(\mu,
\frac{\sigma^{2}}{n}\right), \quad \frac{\bar{x}-\mu}{\sigma / \sqrt{n}}
\sim N(0,1)\)</span></p>
<p><span class="math inline">\(\bar{x}\)</span> 与 <span
class="math inline">\(s^{2}\)</span> 相互独立, 且 <span
class="math inline">\(\frac{(n-1) \cdot s^{2}}{\sigma^{2}} \sim
\chi^{2}(n-1)\)</span>，<span
class="math inline">\(\frac{\frac{\bar{x}-\mu}{\sigma /
\sqrt{n}}}{\sqrt{\frac{(n-1) \cdot s^{2}}{\sigma^{2}}}}\)</span> 可以将
<span class="math inline">\(\sigma\)</span> 的影响消去。</p>
<p><span class="math display">\[
\frac{\frac{\bar{x}-\mu}{\sigma /
\sqrt{n}}}{\sqrt{\frac{(n-1)s^2}{\sigma^2} /(n-1)}}=\frac{\bar{x}-\mu}{s
/ \sqrt{n}}=\frac{\sqrt{n}(\bar{x}-\mu)}{s} \sim t(n-1)
\]</span> 形式上是非常好记下来的。</p>
<p><span class="math inline">\(-t_{1-\frac{\alpha}{2}}(n-1) \leq
\frac{\sqrt{n}(\bar{x}-\mu)}{s} \leq
t_{1-\frac{\alpha}{2}}(n-1)\)</span></p>
<p><span class="math inline">\(\bar{x}-\frac{s}{\sqrt{n}}
t_{1-\frac{\alpha}{2}}(n-1) \leq \mu \leq \bar{x}+\frac{s}{\sqrt{n}}
t_{1-\frac{\alpha}{2}}(n-1)\)</span></p>
<ol start="2" type="1">
<li>求 <span class="math inline">\(\sigma^{2}\)</span> 的 <span
class="math inline">\(1-\alpha\)</span> 置信区间</li>
</ol>
<p><span class="math inline">\(\frac{(n-1) s^{2}}{\sigma^{2}} \sim
\chi^{2}(n-1)\)</span> 可作为枢轴量，<span
class="math inline">\(\left(\chi_{\frac{\alpha}{2}}^{2} \leq \frac{(n-1)
s^{2}}{\sigma^{2}} \leq
\chi_{1-\frac{\alpha}{2}}^{2}\right)=1-\alpha\)</span> <span
class="math display">\[
P\left(\frac{(n-1) s^{2}}{\chi_{1-\frac{\alpha}{2}}^{2}} \leq \sigma^{2}
\leq \frac{(n-1) s^{2}}{\chi_{\frac{\alpha}{2}}^{2}}\right)=1-\alpha
\Rightarrow \sigma^{2} \in\left[\frac{(n-1)
s^{2}}{\chi_{1-\frac{\alpha}{2}}^{2}}, \frac{(n-1)
s^{2}}{\chi_{\frac{\alpha}{2}}^{2}}\right]
\]</span> <strong>去除未知参数的影响</strong></p>
</blockquote>
<ul>
<li>Behrens-Fisher 问题</li>
</ul>
<blockquote>
<p><span class="math inline">\(x_{1}, \cdots, x_{m}\)</span>
来自正态总体 <span class="math inline">\(N\left(\mu_{1}, \sigma_{1}{
}^{2}\right), y_{1}, \cdots, y_{n}\)</span> 来自正态总体 <span
class="math inline">\(N\left(\mu_{2}, \sigma_{2}{ }^{2}\right), \mu_{1}
、 \mu_{2}\)</span> 末知， <span class="math inline">\(\sigma_{1}{
}^{2}=\sigma_{2}{ }^{2}=\sigma^2\)</span> 末知，求 <span
class="math inline">\(\mu_{2}-\mu_{1}\)</span> 的 <span
class="math inline">\(1-\alpha\)</span> 置信区间。</p>
<p><span class="math inline">\(\bar{x} \sim N\left(\mu_{1},
\frac{\sigma^{2}}{m}\right), \bar{y} \sim N\left(\mu_{2},
\frac{\sigma^{2}}{n}\right), \quad \bar{x}-\bar{y} \sim
N\left(\mu_{1}-\mu_{2},
\frac{\sigma^{2}}{m}+\frac{\sigma^{2}}{n}\right)\)</span></p>
<p><span class="math inline">\(\frac{(m-1) s_{x}^{2}}{\sigma^{2}} \sim
\chi^{2}(m-1), \frac{(n-1) s_{y}^{2}}{\sigma^{2}} \sim \chi^{2}(n-1),
\quad \frac{(m-1) s_{x}^{2}}{\sigma^{2}}+\frac{(n-1)
s_{y}^{2}}{\sigma^{2}} \sim \chi^{2}(m+n-2)\)</span></p>
<p><span class="math display">\[
\frac{\frac{(\bar{x}-\bar{y})-\left(\mu_{1}-\mu_{2}\right)}{\sigma
\sqrt{\frac{1}{m}+\frac{1}{n}}}}{\sqrt{\frac{(m-1) s_{x}^{2}+(n-1)
s_{y}^{2}}{\sigma^{2}}
/(m+n-2)}}=\frac{\sqrt{m+n-2}}{\sqrt{\frac{1}{m}+\frac{1}{n}}} \cdot
\frac{(\bar{x}-\bar{y})-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{(m-1)
s_{x}^{2}+(n-1) s_{y}^{2}}} \sim t(m+n-2)
\]</span> <strong>这个问题还可以用渐进正态分布来处理</strong></p>
<p><span
class="math inline">\(\frac{\bar{x}-\bar{y}-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\sigma_{x}^{2}
/ m+\sigma_{y}^{2} / n}} \sim N(0,1), \quad
\frac{\bar{x}-\bar{y}-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{s_{x}^{2} /
m+s_{y}^{2} / n}} \sim N(0,1)\)</span></p>
</blockquote>
<ul>
<li>正态方差之商的区间估计</li>
</ul>
<blockquote>
<p>例 <span class="math inline">\(x_{1}, \cdots, x_{m}\)</span>
来自正态总体 <span class="math inline">\(N\left(\mu_{1},
\sigma_{1}^{2}\right), y_{1}, \cdots, y_{n}\)</span> 来自正态总体 <span
class="math inline">\(N\left(\mu_{2}, \sigma_{2}{ }^{2}\right)\)</span>,
<span class="math inline">\(\mu_{1} 、 \mu_{2}\)</span> 末知， <span
class="math inline">\(\sigma_{1}{ }^{2} 、 \sigma_{2}{ }^{2}\)</span>
末知, 求 <span class="math inline">\(\sigma_{1}{ }^{2} / \sigma_{2}{
}^{2}\)</span> 的区间估计。</p>
<p><span class="math display">\[
\begin{array}{l}
\frac{(m-1) s_{1}{ }^{2}}{\sigma_{1}{ }^{2}} \sim \chi^{2}(m-1), \quad
\frac{(n-1) s_{2}{ }^{2}}{\sigma_{2}{ }^{2}} \sim \chi^{2}(n-1) \\
\Rightarrow \quad F=\frac{s_{1}{ }^{2} / \sigma_{1}{ }^{2}}{s_{2}{ }^{2}
/ \sigma_{2}{ }^{2}} \sim F(m-1, n-1)
\end{array}
\]</span></p>
</blockquote>
<ul>
<li>指数分布的区间分布</li>
</ul>
<blockquote>
<p><span class="math inline">\(x_{1}, \cdots, x_{n}\)</span>
来自指数总体 <span
class="math inline">\(\operatorname{Exp}(\lambda)\)</span>, 求参数 <span
class="math inline">\(\lambda\)</span> 的区间估计</p>
<p>可以证明 <span class="math inline">\(X=2
\lambda\left(x_{1}+\cdots+x_{n}\right) \sim \chi^{2}(2 n) \Rightarrow 2
n \lambda \bar{x} \sim \chi^{2}(2 n)\)</span></p>
<p><span class="math inline">\(P\left(\chi_{\frac{\alpha}{2}}^{2}(2 n)
\leq 2 n \lambda \bar{x} \leq \chi_{1-\frac{\alpha}{2}}^{2}(2
n)\right)=1-\alpha\)</span> <span class="math inline">\(\Rightarrow
\chi_{\frac{\alpha}{2}}^{2}(2 n) \leq 2 n \lambda \bar{x} \leq
\chi_{1-\frac{\alpha}{2}}^{2}(2 n)\)</span> <span
class="math inline">\(\Rightarrow \lambda
\in\left[\chi_{\frac{\alpha}{2}}^{2}(2 n) / 2 n \bar{x},
\chi_{1-\frac{\alpha}{2}}^{2}(2 n) / 2 n \bar{x}\right]\)</span></p>
</blockquote>
<ul>
<li>均匀分布的区间估计</li>
</ul>
<blockquote>
<p><span class="math inline">\(F_{x_{(j)}}(x,
\theta)=\left(\frac{x}{\theta}\right)^{n}, \quad
Y=\frac{x_{(n)}}{\theta}, \quad
F_{Y}(y)=P(Y&lt;y)=P\left(\frac{x_{(n)}}{\theta}&lt;y\right)=y^{n}\)</span></p>
<p><span class="math inline">\(\frac{x_{(n)}}{\theta}\)</span>
可作为枢轴量</p>
<p><span class="math inline">\(P\left(c \leq \frac{x_{(n)}}{\theta} \leq
d\right)=d^{n}-c^{n}=1-\alpha \Rightarrow \frac{x_{(n)}}{d} \leq \theta
\leq \frac{x_{(n)}}{c}\)</span></p>
<p>可取 <span class="math inline">\(d=1, c=\sqrt[n]{\alpha}, \quad
\theta \in\left[x_{(n)},
\frac{x_{(n)}}{\sqrt[n]{\alpha}}\right]\)</span></p>
</blockquote>
<ul>
<li>基于渐进分布的两点分布区间估计</li>
</ul>
<blockquote>
<p>例 样本 <span class="math inline">\(X_{1}, \cdots, X_{n}\)</span>
来自两点分布总体 <span class="math inline">\(\boldsymbol{b}(1,
\boldsymbol{p})\)</span>, 求 <span
class="math inline">\(\boldsymbol{p}\)</span> 的区间估计。
解：样本均值的期望、方差分别为 <span class="math inline">\(E(\bar{X})=p,
\operatorname{Var}(\bar{X})=\frac{p(1-p)}{n}\)</span> 根据中心极限定理当
<span class="math inline">\(n\)</span> 较大时, 有近似分布 <span
class="math inline">\(\bar{X} \dot{\sim} N\left(p,
\frac{p(1-p)}{n}\right)\)</span>, 标准化后得到枢轴量 <span
class="math inline">\(\frac{\bar{X}-p}{\sqrt{\frac{p(1-p)}{n}}}
\dot{\sim} N(0,1)\)</span> <span class="math display">\[
P\left(\left|\frac{\bar{X}-p}{\sqrt{p(1-p) / n}}\right| \leq u_{1
\frac{\alpha}{2}}\right) \approx 1-\alpha, \quad \text { 即
}(\bar{X}-p)^{2} \leq u_{1-\frac{\alpha}{2}}^{2} \frac{p(1-p)}{n}
\]</span> <span
class="math inline">\(\frac{1}{1+c}\left(\bar{X}+\frac{c}{2}-\sqrt{\frac{\bar{X}(1-\bar{X})}{n}
u_{1-\frac{\alpha}{2}}^{2}+\frac{c^{2}}{4}}\right) \leq p \leq
\frac{1}{1+c}\left(\bar{X}+\frac{c}{2}+\sqrt{\frac{\bar{X}(1-\bar{X})}{n}
u_{1-\frac{\alpha}{2}}^{2}+\frac{c^{2}}{4}}\right)\)</span></p>
</blockquote>
<h1 id="假设检验">假设检验</h1>
<ul>
<li>假设检验的基本步骤</li>
</ul>
<blockquote>
<ol type="1">
<li>建立假设 <span class="math inline">\(\mathrm{H}_{0}: \theta \in
\Theta_{0} \quad\)</span> VS <span class="math inline">\(\quad H_{1}:
\theta \in \Theta_{1}\)</span>（原假设和备择假设不一定是对立的）</li>
<li>选择检验统计量, 给出拒绝域的形式——所谓拒绝域
W是指使原假设被拒绝的样本观测值所在的区域, 有时也将 <span
class="math inline">\(\overline{\mathbf{W}}\)</span> 称为接受域。</li>
<li>选择显著性水平 <span class="math inline">\(\alpha\)</span>
(具体异常到什么程度拒绝原假设)。其定义为 <span
class="math inline">\(\alpha=\max
\left\{\mathrm{P}\left(\right.\right.\)</span> 拒绝 <span
class="math inline">\(\mathrm{H}_{0} \mid \mathrm{H}_{0}\)</span> 为真
<span class="math inline">\(\left.)\right\}=\max
\left\{\mathrm{P}_{\theta}(\mathrm{X} \in \mathbf{W}),
\boldsymbol{\theta} \in
\Theta_{0}\right\}\)</span>，也即原假设成立时被拒绝的概率的最大值。（如果原假设是
<span class="math inline">\(\mu \ge const\)</span>，那么 <span
class="math inline">\(\alpha\)</span> 就是取最大值，一般就在 <span
class="math inline">\(\mu=const\)</span> 时取到，如果原假设就是 <span
class="math inline">\(\mu=const\)</span>，那么 <span
class="math inline">\(\alpha\)</span> 就是 <span
class="math inline">\(\mu=const\)</span> 时被拒绝的概率）</li>
<li>给出拒绝域的具体范围。</li>
</ol>
</blockquote>
<ul>
<li>两类错误</li>
</ul>
<blockquote>
<p>第一类错误 <span
class="math inline">\(\alpha(\theta)=\mathrm{P}\left(\right.\)</span>
拒绝 <span class="math inline">\(\mathrm{H}_{0} \mid
\mathrm{H}_{0}\)</span> 为真 <span
class="math inline">\()=\mathrm{P}_{\theta}(\mathrm{X} \in \mathrm{W}),
\theta \in \Theta_{0}\)</span></p>
<p>第二类错误 <span
class="math inline">\(\beta(\theta)=P\left(\right.\)</span> 接受 <span
class="math inline">\(H_{0} \mid H_{1}\)</span> 为真 <span
class="math inline">\()=P_{\theta}(X \in \bar{W}), \theta \in
\Theta_{1}\)</span></p>
<p>举个例子：</p>
<p>对均匀总体 <span class="math inline">\(U(0, \theta)\)</span>
做假设检验, 原假设与备择假设分别为 <span class="math inline">\(H_{0}:
\theta=5, H_{1}: \theta&lt;5\)</span>, 以 <span
class="math inline">\(x_{(n)}=\max \left\{x_{1}, \cdots,
x_{n}\right\}\)</span> 为检验统计量, 显著性水平 <span
class="math inline">\(\alpha=0.064\)</span>, 若样本容量 <span
class="math inline">\(\boldsymbol{n}=\mathbf{3}\)</span>, 则拒绝域为</p>
<p>解: 只需要根据 <span class="math inline">\(\alpha\)</span>
的定义，原假设为真时，拒绝检验统计量的最大概率。</p>
<p><span
class="math inline">\(P\left(x_{(n)}&lt;c\right)=\left(\frac{c}{5}\right)^{n}=\alpha
\Rightarrow\left(\frac{c}{5}\right)^{3}=0.064 \Rightarrow c=2,
\quad\left\{\left(x_{1}, x_{2}, x_{3}\right):
x_{(3)}&lt;2\right\}\)</span></p>
</blockquote>
<ul>
<li>U 检测（方差已知）</li>
</ul>
<blockquote>
<p>正态总体 <span class="math inline">\(N\left(\mu, \sigma^{2}\right),
\mu\)</span> 末知, <span class="math inline">\(\sigma^{2}\)</span> 已知,
对 <span class="math inline">\(\mu\)</span> 做检验 检 验 统 计 量 <span
class="math inline">\(: u=\frac{\bar{x}-\mu_{0}}{\sigma /
\sqrt{n}}=\frac{\sqrt{n}\left(\bar{x}-\mu_{0}\right)}{\sigma} \sim
N(0,1)\)</span></p>
<p><span class="math inline">\(H_{0}: \mu=\mu_{0} ; \quad H_{1}: \mu
\neq \mu_{0} \quad\)</span> 拒绝域 <span
class="math inline">\(\bar{x}&gt;\mu_{0}+\frac{\sigma}{\sqrt{n}}
u_{1-\frac{\alpha}{2}}\)</span> 或 <span
class="math inline">\(\bar{x}&lt;\mu_{0}-\frac{\sigma}{\sqrt{n}}
u_{1-\frac{\alpha}{2}}\)</span></p>
<p><span class="math inline">\(H_{0}: \mu \geq \mu_{0} ; \quad H_{1}:
\mu&lt;\mu_{0} \quad\)</span> 拒绝域 <span
class="math inline">\(\bar{x}&lt;\mu_{0}-\frac{\sigma}{\sqrt{n}}
u_{1-\alpha}\)</span></p>
<p><span class="math inline">\(H_{0}: \mu \leq \mu_{0} ; \quad H_{1}:
\mu&gt;\mu_{0} \quad\)</span> 拒绝域 <span
class="math inline">\(\bar{x}&gt;\mu_{0}+\frac{\sigma}{\sqrt{n}}
u_{1-\alpha}\)</span></p>
</blockquote>
<ul>
<li>t 检测（方差未知）</li>
</ul>
<blockquote>
<p>正态总体 <span class="math inline">\(N\left(\mu, \sigma^{2}\right),
\mu\)</span> 末知, <span class="math inline">\(\sigma^{2}\)</span> 末知,
对 <span class="math inline">\(\mu\)</span> 做检验，检验统计量 <span
class="math inline">\(t=\frac{\bar{x}-\mu_{0}}{s /
\sqrt{n}}=\frac{\sqrt{n}\left(\bar{x}-\mu_{0}\right)}{s} \sim
t(n-1)\)</span> <span class="math display">\[
\begin{array}{ll}
H_{0}: \mu=\mu_{0} ; \quad H_{1}: \mu \neq \mu_{0} &amp; \text { 拒绝域
} \bar{x}&gt;\mu_{0}+\frac{\sigma}{\sqrt{n}} t_{1-\frac{\alpha}{2}}(n-1)
\text { 或 } \bar{x}&lt;\mu_{0}-\frac{\sigma}{\sqrt{n}}
t_{1-\frac{\alpha}{2}}(n-1) \\
H_{0}: \mu \geq \mu_{0} ; H_{1}: \mu&lt;\mu_{0} &amp; \text { 拒绝域 }
\bar{x}&lt;\mu_{0}-\frac{\sigma}{\sqrt{n}} t_{1-\alpha}(n-1) \\
H_{0}: \mu \leq \mu_{0} ; H_{1}: \mu&gt;\mu_{0} &amp; \text { 拒绝域 }
\bar{x}&gt;\mu_{0}+\frac{\sigma}{\sqrt{n}} t_{1-\alpha}(n-1)
\end{array}
\]</span></p>
</blockquote>
<ul>
<li>p 值（更异常的概率）</li>
</ul>
<blockquote>
<p>检验的 p 值: 在一个假设检验问题中,
利用样本观测值能够做出拒绝原假设的最小显著性水平;
<strong>即原假设成立条件下,
检验统计量出现在比观测值更异常的范围的概率的最大值</strong></p>
<p>所谓更异常，指的是更偏向备择假设的那个方向。</p>
<p>判断产品是否优质的问题 <span class="math inline">\(H_{0}: \mu \geq
10\)</span> vs <span class="math inline">\(H_{1}: \mu&lt;10\)</span>;
两次观测结果 <span class="math inline">\(\bar{x}=9.3,
\bar{x}=10.15\)</span></p>
<p>p 值分别为 <span class="math display">\[
\begin{array}{l}
p_{1}=P(\bar{x} \leq 9.3)=P\left(\frac{\bar{x}-10}{1 / 2} \leq
\frac{9.3-10}{1 / 2}\right)=\Phi(-1.4)=0.081 \\
p_{2}=P(\bar{x} \leq 10.15)=P\left(\frac{\bar{x}-10}{1 / 2} \leq
\frac{10.15-10}{1 / 2}\right)=\Phi(0.3)=0.618
\end{array}
\]</span></p>
</blockquote>
<h1 id="拟合优度检验与贝叶斯估计">拟合优度检验与贝叶斯估计</h1>
<ul>
<li>势函数</li>
</ul>
<blockquote>
<p>检验问题 <span class="math inline">\(\mathrm{H}_{0}: \theta \in
\Theta_{0} \quad\mathrm{ VS } \quad \mathrm{H}_{1}: \theta \in
\Theta_{1}\)</span> 拒绝域为 <span class="math inline">\(\mathrm{X} \in
\mathrm{W}\)</span> 该检验的势函数: <span
class="math inline">\(\mathbf{g}(\theta)=P_{\theta}(X \in
W)\)</span></p>
<p>第一类错误 <span
class="math inline">\(\alpha(\theta)=\mathrm{P}\left(\right.\)</span>
拒绝 <span class="math inline">\(\mathrm{H}_{0} \mid
\mathrm{H}_{0}\)</span> 为真 <span
class="math inline">\()=\mathrm{P}_{\theta}(\mathrm{X} \in \mathrm{W}),
\theta \in \Theta_{0}\)</span></p>
<p>第二类错误 <span
class="math inline">\(\beta(\theta)=P\left(\right.\)</span> 接受 <span
class="math inline">\(H_{0} \mid H_{1}\)</span> 为真 <span
class="math inline">\()=P_{\theta}(X \in \bar{W}), \theta \in
\Theta_{1}\)</span> <span class="math display">\[
g(\theta)=\left\{\begin{array}{cc}
\alpha(\theta), &amp; \theta \in \Theta_{0} \\
1-\beta(\theta), &amp; \theta \in \Theta_{1}
\end{array}\right.
\]</span> 如果对任意的 <span class="math inline">\(\theta \in
\Theta_{0}\)</span>，都有 <span class="math inline">\(\mathrm{g}(\theta)
\leq \alpha\)</span>，则称该检验是显著性水平为 <span
class="math inline">\(\alpha\)</span> 的显著性检验，简称显著性水平为
<span class="math inline">\(\alpha\)</span> 的检验或水平为 <span
class="math inline">\(\alpha\)</span> 的检验</p>
</blockquote>
<ul>
<li>拟合优度检验</li>
</ul>
<blockquote>
<p>K.Pearson 的 <span class="math inline">\(\chi^{2}\)</span> 检验</p>
<p>设总体服从离散分布：</p>
<p><span class="math inline">\(\begin{array}{cccc}\boldsymbol{X} &amp;
\boldsymbol{x}_{1} &amp; \cdots &amp; \boldsymbol{x}_{k} \\
\boldsymbol{P} &amp; \boldsymbol{p}_{1} &amp; \cdots &amp;
\boldsymbol{p}_{k}\end{array}\)</span></p>
<p>进行 <span class="math inline">\(n\)</span> 次独立地观测, <span
class="math inline">\(k\)</span> 个取值出现的频次分别为 <span
class="math inline">\(N_{i}(i=1, \cdots, k)\)</span>, 则 <span
class="math inline">\(X=\sum_{i=1}^{k} \frac{\left(N_{i}-n
p_{i}\right)^{2}}{n p_{i}}\)</span> 近似服从自由度为 <span
class="math inline">\(k-1\)</span> 的 <span
class="math inline">\(\chi^{2}\)</span> 分布。若需要通过样本估计 <span
class="math inline">\(\mathrm{s}\)</span> 个参数，则 <span
class="math inline">\(X=\sum_{i=1}^{\mathrm{n}} \frac{\left(N_{i}-N
p_{i}\right)^{2}}{N p_{i}}\)</span> 近似服从自由度 <span
class="math inline">\(\mathrm{k}-\mathrm{s}-1\)</span> 的卡方分布。</p>
</blockquote>
<ul>
<li>列联表检测</li>
</ul>
<blockquote>
<p>行 <span class="math inline">\(c_i\)</span>，列 <span
class="math inline">\(d_i\)</span> <span class="math display">\[
Y=\sum_{i=1}^{s} \sum_{j=1}^{t} \frac{\left(n_{i j}-n \cdot
\frac{c_{i}}{n} \cdot \frac{d_{j}}{n}\right)^{2}}{n \cdot
\frac{c_{i}}{n} \cdot \frac{d_{j}}{n}}=\sum_{i=1}^{s} \sum_{j=1}^{t}
\frac{\left(n n_{i j}-c_{i} d_{j}\right)^{2}}{n c_{i} d_{j}}
\]</span> 近似服从自由度为 <span
class="math inline">\((s-1)(t-1)\)</span> 的 <span
class="math inline">\(\chi^{2}\)</span> 分布</p>
</blockquote>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2022%E6%98%A5%E5%AD%A3/">2022春季</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-62b11572b25ab3ab" async="async"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/06/Lecture/2022%20Spring/deep_learning/"><img class="prev-cover" src="https://pic.imgdb.cn/item/61f0fc662ab3f51d9172fef0.jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Oscar Rodrigo Hernandez Panczenko (P0GQ95huhBo).jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Segement Me If U Can</div></div></a></div><div class="next-post pull-right"><a href="/2022/06/04/CS/%E7%A7%91%E7%A0%94/%E5%A4%A7%E4%BA%8C%E5%AD%A6%E5%B9%B4/Gau%20GAN/"><img class="next-cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Cassie Boca (gFyy2Po7T-k).jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Oscar Rodrigo Hernandez Panczenko (P0GQ95huhBo).jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Understanding Gau GAN</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/02/23/Lecture/2022%20Spring/probability/" title="Probability"><img class="cover" src="https://pic.imgdb.cn/item/61eccc372ab3f51d91d6e87d.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-23</div><div class="title">Probability</div></div></a></div><div><a href="/2022/04/02/Lecture/2022%20Spring/distribution/" title="Distribution Is All U Need"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Simon Berger (5EB1k3iCsJM).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-02</div><div class="title">Distribution Is All U Need</div></div></a></div><div><a href="/2022/03/22/Lecture/2022%20Spring/Computer_graphics/" title="Computer Graphics"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Dahee Son (tV06QVJXVxU).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-22</div><div class="title">Computer Graphics</div></div></a></div><div><a href="/2022/05/25/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%94%E9%83%A8/" title="清华园日记——第五部"><img class="cover" src="https://zhaochenyang20.github.io/pic/embed/5_31_1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-25</div><div class="title">清华园日记——第五部</div></div></a></div><div><a href="/2022/05/17/Lecture/2022%20Spring/binaryDivdence/" title="深度学习基础"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by John O'Nolan (6f_ANCcbj3o).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-17</div><div class="title">深度学习基础</div></div></a></div><div><a href="/2022/03/15/Lecture/2022%20Spring/Introduction_to_AI/" title="Introduction to Artificial Intelligence"><img class="cover" src="https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-15</div><div class="title">Introduction to Artificial Intelligence</div></div></a></div><div><a href="/2022/05/24/Lecture/2022%20Spring/Reinforcement/" title="重力四子棋"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Lee Roylland (dfZbts6B4yw).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-24</div><div class="title">重力四子棋</div></div></a></div><div><a href="/2022/06/06/Lecture/2022%20Spring/deep_learning/" title="Segement Me If U Can"><img class="cover" src="https://pic.imgdb.cn/item/61f0fc662ab3f51d9172fef0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-06</div><div class="title">Segement Me If U Can</div></div></a></div><div><a href="/2022/03/31/%E5%87%BA%E5%9B%BD/%E9%A1%B9%E8%84%8A%E8%BD%A9%E5%BF%97/" title="临别项脊轩"><img class="cover" src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Tim Marshall (bvuwsIUCksA).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-31</div><div class="title">临别项脊轩</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#readme"><span class="toc-number">1.</span> <span class="toc-text">readme</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">2.</span> <span class="toc-text">统计学基本概念</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E7%82%B9%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%96%B9%E6%B3%95%E4%B8%8E%E8%AF%84%E4%BB%B7"><span class="toc-number">3.</span> <span class="toc-text">参数点估计的方法与评价</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1"><span class="toc-number">4.</span> <span class="toc-text">参数区间估计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C"><span class="toc-number">5.</span> <span class="toc-text">假设检验</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8B%9F%E5%90%88%E4%BC%98%E5%BA%A6%E6%A3%80%E9%AA%8C%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1"><span class="toc-number">6.</span> <span class="toc-text">拟合优度检验与贝叶斯估计</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background: ＃0096FF"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Eren Zhao</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><script type="text/javascript" id="maid-script" src="https://unpkg.com/mermaid@undefined/dist/mermaid.min.js?v=undefined"></script><script>if (window.mermaid) {
  var options = JSON.parse(document.getElementById('maid-script').getAttribute('mermaidoptioins'));
  mermaid.initialize(options);
}</script></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库正在艰难运行</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '978121c7b834efdd76be',
      clientSecret: '59b40e8f39a1c33db5a2c891771086164b9575c4',
      repo: 'zhaochenyang20.github.io',
      owner: 'zhaochenyang20',
      admin: ['zhaochenyang20'],
      id: 'f18f772ff0e92001bd127a2a9a541a6c',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/"});</script></body></html>