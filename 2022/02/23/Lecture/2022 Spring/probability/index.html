<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Probability | 求道之人，不问寒暑</title><meta name="keywords" content="2022春季,数学"><meta name="author" content="Eren Zhao"><meta name="copyright" content="Eren Zhao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="梁老师教的蛮好，你把他退了干嘛？">
<meta property="og:type" content="article">
<meta property="og:title" content="Probability">
<meta property="og:url" content="http://example.com/2022/02/23/Lecture/2022%20Spring/probability/index.html">
<meta property="og:site_name" content="求道之人，不问寒暑">
<meta property="og:description" content="梁老师教的蛮好，你把他退了干嘛？">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Matteo Catanese (qAQLykbTGeg).jpg">
<meta property="article:published_time" content="2022-02-23T01:36:57.327Z">
<meta property="article:modified_time" content="2022-08-26T16:19:47.590Z">
<meta property="article:author" content="Eren Zhao">
<meta property="article:tag" content="2022春季">
<meta property="article:tag" content="数学">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Matteo Catanese (qAQLykbTGeg).jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://example.com/2022/02/23/Lecture/2022%20Spring/probability/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"麻了，找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Probability',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2022-08-27 00:19:47'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/mouse.css"><meta name="generator" content="Hexo 6.0.0"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}</style></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend.jpg'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">190</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">51</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">30</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/list-100/"><i class="fa-fw fas fa-music"></i><span> TODO</span></a></div><div class="menus_item"><a class="site-page" href="/projects/"><i class="fa-fw fas fa-video"></i><span> Projects</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Matteo Catanese (qAQLykbTGeg).jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">求道之人，不问寒暑</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/list-100/"><i class="fa-fw fas fa-music"></i><span> TODO</span></a></div><div class="menus_item"><a class="site-page" href="/projects/"><i class="fa-fw fas fa-video"></i><span> Projects</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Probability</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-02-23T01:36:57.327Z" title="发表于 2022-02-23 09:36:57">2022-02-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-26T16:19:47.590Z" title="更新于 2022-08-27 00:19:47">2022-08-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B/">课程</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B/%E6%A6%82%E7%BB%9F/">概统</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>23分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Probability"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="readme">readme</h1>
<ul>
<li>梁衡老师的概统讲的很好，<del>少数我想线下听的课</del>，可惜也没好好听</li>
<li>听人说，梁衡老师的考试很能区分你听没听课，下没下功夫，反正没见人 rush 成功的</li>
<li>把时间用在小测和习题课上可比卷美赛国赛好多了</li>
<li>概统对机器学习意义大多了</li>
<li>我总结下每一章比较有意思的地方，这一部分是概率部分，统计部分见其他篇章</li>
<li>在写这篇博客的时候，我的图床挂了一次，吓得我赶快换了个图床，瞎折腾了很久，学会了博客内镶图床</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhaochenyang20.github.io/pic/embed/spring4.jpg" style="zoom:33%;" /></p>
<ul>
<li>这张照片是我的好朋友一多在伦敦拍的，祝他春假快乐</li>
</ul>
<h1 id="课程学习的观念">课程学习的观念</h1>
<ul>
<li><p>数学成熟的提升：</p>
<blockquote>
<p>用到数学的时候我不会害怕，真的知道它，它是你的工具，你能够驾驭</p>
</blockquote></li>
<li><p>什么是微积分：</p>
<blockquote>
<p>微积分（Calculus），数学概念，是高等数学中研究函数的微分(Differentiation)、积分(Integration)以及有关概念和应用的数学分支。 它是数学的一个基础学科，内容主要包括极限、微分学、积分学及其应用。 微分学包括求导数的运算，是一套关于变化率的理论。</p>
</blockquote></li>
<li><p>课堂笑话：</p>
<blockquote>
<p>你是个程序员，说出来就放你走，说不出来就枪毙你！</p>
<p>js 里 9+“1” 等于多少？</p>
</blockquote></li>
</ul>
<h1 id="lecture-1-引言">Lecture 1 引言</h1>
<p><span class="math display">\[
\sum_{k=1}^{n}k\times C^k_n=n\times 2^{n-1}\\
对(x+1)^n = \sum^n_{k=0}C^L_N\times x^k求导
\]</span></p>
<p>可以参考<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=wkFm2K8mvmg">这个</a>。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%A4%BA%E6%80%A7%E5%87%BD%E6%95%B0">示性函数</a>，P21</li>
<li>P26 页例子，经典的利用不大于作差得到恰好关系的例子</li>
<li>P27 页，整道题都值得打磨</li>
</ul>
<blockquote>
<ol type="1">
<li>事件的表示</li>
<li>超集大小的算法</li>
<li><span class="math inline">\(P(A_{i_1}\dots A_{i_k})\)</span> 的算法与独立性</li>
<li><span class="math inline">\(\sum^{n}_{1}P(A_i)=1\)</span></li>
<li><span class="math inline">\(e^x\)</span> 的展开</li>
</ol>
</blockquote>
<h1 id="lecture-2-条件概率">Lecture 2 条件概率</h1>
<ul>
<li>P4，经典问题，参考阶段自测</li>
<li>P8，严谨的概率语言——三次都是白色的概率必然建立在之前抽到的每一次都是白色，所以是条件概率</li>
<li>P10，全概率公式的定义</li>
<li>P15，贝叶斯公式直观理解</li>
<li>P17，经典问题，虚惊一场的概率高到 70%</li>
<li>P18，转换为独立无穷概率求和</li>
<li>P22，类比多元统计的相互独立性，第 6 章 P</li>
<li>P23，相关系数</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/70154991">事件的相关系数</a></li>
</ul>
<blockquote>
<p>对于任意事件 <span class="math inline">\(A\)</span>, 可以定义一个与之相关的随机变量 <span class="math inline">\(X_{A}\)</span> : 当事件 <span class="math inline">\(A\)</span> 发生时, <span class="math inline">\(X_{A}\)</span> 取1, 否则取 0。于是数学期望 <span class="math inline">\(\mathbb{E} X_{A}=P(A)\)</span>, 方差 <span class="math inline">\(\operatorname{var}\left[X_{A}\right]=P(A) P(\bar{A})\)</span> 。 对于两个事件 <span class="math inline">\(A, B\)</span>, 可以考察相应随机变量的协方差与相关系数 <span class="math display">\[
\begin{array}{l}
\operatorname{cov}\left(X_{A}, X_{B}\right)=P(A B)-P(A) P(B) \\
\operatorname{corr}\left(X_{A}, X_{B}\right)=\frac{P(A B)-P(A) P(B)}{\sqrt{P(A) P(\bar{A}) P(B) P(\bar{B})}}
\end{array}
\]</span> 定义两个事件的相关系数 <span class="math inline">\(\chi(A, B)=\operatorname{corr}\left(X_{A}, X_{B}\right)\)</span> 。</p>
<p>经过一些数学整理可得 <span class="math display">\[
P(A B) P(\bar{A} \bar{B})-P(\bar{A} B) P(A \bar{B})=P(A B)-P(A) P(B)
\]</span> 于是可以得到相关系数的一个等价表示 <span class="math display">\[
\chi(A, B)=\frac{P(A B) P(\bar{A} \bar{B})-P(\bar{A} B) P(A \bar{B})}{\sqrt{P(A) P(\bar{A}) P(B) P(\bar{B})}}
\]</span></p>
</blockquote>
<h1 id="lec-3-离散型随机变量">Lec 3 离散型随机变量</h1>
<ul>
<li>P4，随机变量：定义在样本空间上的函数，随机变量是函数——样本的定量表达</li>
<li>P6，示性函数</li>
<li>P8，分布函数的定义，边界情况，区分 <span class="math inline">\(F\)</span> 与 <span class="math inline">\(P\)</span></li>
</ul>
<p><span class="math display">\[
\forall x,F(x)=P(X\le x)
\]</span></p>
<ul>
<li>P10，分布列，可列分布</li>
<li>P12，伯努利分布</li>
<li>P14，二项分布——分布列类似钟形，分布函数类似高中生物的 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/S%E5%9E%8B%E5%A2%9E%E9%95%BF%E6%9B%B2%E7%BA%BF/12979174">S 形曲线</a></li>
</ul>
<blockquote>
<p><span class="math display">\[
f(k, n, p)=\operatorname{Pr}(X=k)=\left(\begin{array}{l}
n \\
k
\end{array}\right) p^{k}(1-p)^{n-k}
\]</span> 对于 <span class="math inline">\(k=0,1,2, \ldots, n\)</span>, 其中 <span class="math inline">\(\left(\begin{array}{l}n \\ k\end{array}\right)=\frac{n !}{k !(n-k) !}\)</span></p>
<p>累积分布函数可以表示为: <span class="math display">\[
F(x ; n, p)=\operatorname{Pr}(X \leq x)=\sum_{i=0}^{\lfloor x\rfloor}\left(\begin{array}{c}
n \\
i
\end{array}\right) p^{i}(1-p)^{n-i}
\]</span> 其中 <span class="math inline">\(\lfloor x\rfloor\)</span> 是小于或等于 <span class="math inline">\(x\)</span> 的最大整数。</p>
<p>如果 <span class="math inline">\(X \sim B(n, p)\)</span> (也就是说, <span class="math inline">\(X\)</span> 是服从二项分布的随机变量）, 那么X的期望值为 <span class="math inline">\(\mathrm{E}[X]=n p\)</span>。方差为 <span class="math inline">\(\operatorname{Var}[X]=n p(1-p)\)</span>。</p>
</blockquote>
<ul>
<li>P17，Poisson Distribution，泊松分布——<strong>小概率事件被大量重复时的近似</strong></li>
<li>先有泊松定理（P20），也即泊松近似，之后整理为泊松分布</li>
</ul>
<p><span class="math display">\[
近似若  X \sim B(n, p), Y \sim P(n p) , 则  P(X=k) \approx P(Y=k),
 \hat{\nabla} \lambda=\mathrm{np} ,\\ 则  \frac{B_{k}(n, p)}{B_{k-1}(n, p)}=\frac{\lambda-(k-1) p}{k(1-p)} \approx \frac{\lambda}{k} 
\\同时 B_{0}(n, p)=(1-p)^{n}=\left(1-\frac{\lambda}{n}\right)^{n}=\left(1+\left(-\frac{\lambda}{n}\right)\right)^{\left(-\frac{n}{\lambda}\right)(-\lambda)} \approx e^{-\lambda} \\
 B_{1}(n, p) \approx \lambda B_{0}(n, p) \approx \lambda e^{-\lambda}, B_{2}(n, p) \approx \frac{\lambda}{2} B_{1}(n, p) \approx \frac{\lambda^{2}}{2} e^{-\lambda}, \cdots, \\B_{k}(n, p) \approx \frac{\lambda^{k}}{k !} e^{-\lambda}
\]</span></p>
<blockquote>
<p>其实这个形式还蛮好记的，毕竟 <span class="math inline">\(\frac{\lambda^k}{k!}\)</span> 是 <span class="math inline">\(e^{\lambda}\)</span> 的泰勒展开。</p>
</blockquote>
<ul>
<li>P27，<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B9%BE%E4%BD%95%E5%88%86%E4%BD%88">几何分布</a></li>
</ul>
<p><span class="math display">\[
p_{X}(k)=(1-p)^{k-1} p, \quad k=1,2, \cdots
\]</span></p>
<ul>
<li>P28，几何分布的无记忆性，无记忆性则符合几何分布</li>
</ul>
<blockquote>
<p>如果随机变量X ~ Ge(p)，则对于任意非负整数s, t，有： <span class="math display">\[
P(X&gt;s+t|X&gt;s)=P(X&gt;t)
\]</span></p>
</blockquote>
<ul>
<li>P30，<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83">负二项分布</a>——关于组合数的扩展定义</li>
</ul>
<blockquote>
<p>负二项分布（Negative binomial distribution）是<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/統計學">统计学</a>上一种描述在一系列独立同分布的伯努利试验中，<strong>成功次数到达指定次数（记为 r ）时总共实验(失败)次数的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/离散概率分布">离散概率分布</a></strong>。比如，如果我们定义掷骰子随机变量 x 值为 x=1 时为成功，所有 x≠1 为失败，这时我们反复掷骰子直到 1 出现 3 次（成功次数 r = 3 ），此时非 1 数字出现次数的概率分布即为负二项分布。</p>
</blockquote>
<p>例一、假设随机变量 <span class="math inline">\(X \sim N b(6,0.05)\)</span>, 则 <span class="math inline">\(E(X)=(\quad)\quad Var(X)=(\quad)\)</span> <span class="math display">\[
X_{1}, \cdots, X_{6} \sim G e(0.05), \quad E(X)=E\left(X_{1}+\cdots+X_{6}\right)=6 \cdot \frac{1}{0.05}=120\\
Var(X)=Var(X_{1}+\cdots+X_{6})=6\cdot \frac{1-p}{p^2}=2280
\]</span></p>
<p>例二、<span class="math inline">\(X_{1}+X_{2}+\cdots+X_{n} \sim N b(n, p)\)</span> <span class="math display">\[
P\left(X_{1}+X_{2}+\cdots+X_{n}=k\right)=\left(\begin{array}{c}
k-1 \\
n-1
\end{array}\right) p^{n}(1-p)^{k-n}, \quad k \geq n
\]</span> &gt; 一共要成功 n 次，每次实验成功的概率为 p，统共实验 k 次的概率，也即前 k - 1 次需要成功 n - 1 次，一共成功 n 次，但是最后一次必然成功。 &gt; &gt; 形式上和二项分布相似，概率意义上与几何分布更密切。首先注意概率意义，其次是数学形式:smile:</p>
<h1 id="lecture-4-连续性离散变量">Lecture 4 连续性离散变量</h1>
<ul>
<li>P4，分布函数的基本性质——单调有界，右连续</li>
<li><ul>
<li>任意分布函数都是<strong>右</strong>连续的</li>
</ul></li>
</ul>
<blockquote>
<p><span class="math inline">\(P(X=a)=F(a)-F(a-0)\)</span></p>
</blockquote>
<ul>
<li>P6，连续型随机变量的定义，概率密度函数的定义，probability density function</li>
<li>连续型随机变量某点的取值不等于概率，某段积分值才等于概率</li>
<li>P8，柯西分布，没有期望，没有平均值，<span class="math inline">\(F(x)=\frac{arctan(x)+\frac{\pi}{2}}{\pi}\)</span></li>
</ul>
<p><span class="math display">\[
p(x)=\frac{1}{\pi}\times \frac{1}{1+x^2}
\]</span></p>
<ul>
<li>P9 与 P10，P 9 是有记忆性的，P 10 是无记忆性—— P9 不是指数分布</li>
<li>P10，指数分布与几何分布具有无记忆性</li>
</ul>
<p><span class="math display">\[
PDF:f_{X}(x)=\left\{\begin{array}{ll}
\lambda \mathrm{e}^{-\lambda x}, &amp; \text { 若 } x \geqslant 0 \\
0, &amp; \text { 其他 }
\end{array}\right.\\CDF:F(x)=1-e^{-\lambda x}\\P(x\ge t)=e^{-\lambda t}
\]</span></p>
<blockquote>
<p>感谢华子大学给我打下的优秀数理基础，我现在一点积分都不会做了，给几个积分，直接背下来，遇到不会就换元 <span class="math display">\[
\int_{0}^{+\infty} x \cdot e^{-x} d x=\int_{0}^{+\infty} e^{-x} d x=1
\\\int_{0}^{+\infty} x^2\cdot e^{-x} d x=2\\\int_{0}^{+\infty} x^n \cdot e^{-x} d x=n!
\]</span></p>
</blockquote>
<ul>
<li>P13，证明指数分布与几何分布的联系，服从参数为 <span class="math inline">\(1-e^{-\lambda}\)</span> 的几何分布</li>
<li>大量的独立同分布的随机变量(不必须为正态)的和的分布近似地服从正态分布，而这个事实与各个和项的具体分布无关，此即<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86">中心极限定理，CLT 定理</a></li>
</ul>
<blockquote>
<p>设 <span class="math inline">\(X_{1}, X_{2} \cdots\)</span> 是独立同分布的随机变量序列, 序列的每一项的均值为 <span class="math inline">\(\mu\)</span>, 方 差为 <span class="math inline">\(\sigma^{2}\)</span>. 记 <span class="math display">\[
Z_{n}=\frac{X_{1}+\cdots+X_{n}-n \mu}{\sqrt{n} \sigma} .
\]</span> 则 <span class="math inline">\(Z_{n}\)</span> 的分布函数的极限分布为标准正态分布函数 <span class="math display">\[
\Phi(x)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{x} \mathrm{e}^{-z^{2} / 2} \mathrm{~d} z,
\]</span> 即 <span class="math inline">\(\lim _{n \rightarrow \infty} \mathrm{P}\left(Z_{n} \leqslant x\right)=\Phi(x)\)</span> 对任意的 <span class="math inline">\(x\)</span> 成立.</p>
<p>很好理解，因为期望是直接相加的，而独立的变量间方差也是直接相加，但是正态分布还要除以标准差，所以要开根号。</p>
<p>比如扔骰子，每个面出现的概率不是正态分布，但是扔 100000 次的和符合正态分布。一般的，<span class="math inline">\(B(n,p)\)</span> 近似于 <span class="math inline">\(N(np,np(1-p))\)</span></p>
</blockquote>
<ul>
<li><p>P17，正态分布的定义，经验法则：68%，95%,99.7%…</p></li>
<li><p>P23，随机变量函数的分布</p></li>
</ul>
<blockquote>
<p>计算连续随机变量 <span class="math inline">\(X\)</span> 的函数 <span class="math inline">\(Y=g(X)\)</span> 的概率密度函数 (PDF)</p>
<p>使用如下公式计算 <span class="math inline">\(Y\)</span> 的概率函数 (CDF) <span class="math inline">\(F_{Y}\)</span>:</p>
<p><span class="math display">\[
Y=g(X)\Rightarrow F_Y(y)=P(g(X)\le y)=\int_{\{x \mid g(x) \leqslant y\}} f_{X}(x) \mathrm{d} x .
\]</span> 对 <span class="math inline">\(F_{Y}\)</span> 求导, 得到 <span class="math inline">\(Y\)</span> 的 <span class="math inline">\(\mathrm{PDF}\)</span> : <span class="math display">\[
f_{Y}(y)=\frac{\mathrm{d} F_{Y}}{\mathrm{~d} y}(y) .
\]</span></p>
<p>同样，对于多元变量的函数也如此。设随机变量 <span class="math inline">\(X, Y\)</span> 独立且均在 <span class="math inline">\((0,6)\)</span> 上服从均匀分布, 则 <span class="math inline">\(\operatorname{Var}(\min (X, Y))=(\quad)\)</span></p>
<p>由题设可知, <span class="math inline">\(F_{X}(x)=\left\{\begin{array}{cc}0, &amp; x \leq 0 . \\ \frac{x}{\theta}, &amp; 0&lt;x&lt;\theta . \\ 1, &amp; x \geq \theta .\end{array}\right.\)</span> <span class="math display">\[
\text { 且 } F_{Z}(z)=P(\min (X, Y)&lt;z)=1-\left(1-F_{X}(z)\right)^{2}\\=\left\{\begin{array}{cc}
0, &amp; z \leq 0 . \\
\frac{2 z}{\theta}-\frac{z^{2}}{\theta^{2}}, &amp; 0&lt;z&lt;\theta . \\
1, &amp; z \geq \theta .
\end{array}\right.
\]</span> 于是 <span class="math inline">\(Z\)</span> 的密度函数为 <span class="math inline">\(p(z)=F_{Z}^{\prime}(z)=\left\{\begin{array}{cc}\frac{2}{\theta}-\frac{2 z}{\theta^{2}}, &amp; 0&lt;z&lt;\theta, \\ 0, &amp; \text { 其他. }\end{array}\right.\)</span> <span class="math display">\[
\operatorname{Var}[\min (X, Y)]=E\left(Z^{2}\right)-(E(Z))^{2}=\\\int_{0}^{\theta} z^{2}\left(\frac{2}{\theta}-\frac{2 z}{\theta^{2}}\right) \mathbf{d} z-\left(\int_{0}^{\theta} z\left(\frac{2}{\theta}-\frac{2 z}{\theta^{2}}\right) \mathbf{d} z\right)^{2}\\=\frac{2 \theta^{2}}{3}-\frac{\theta^{2}}{2}-\left(\theta-\frac{2 \theta}{3}\right)^{2}=\frac{\theta^{2}}{18}
\]</span></p>
</blockquote>
<ul>
<li>P25，据 y 和 g(X) 性质，反解出 X 的取值范围，然后做不定积分等等求出这个范围内的 P(X)</li>
<li>P27，感觉这一块梁老师的课件讲的不太清楚，我之后会给他说一声</li>
<li>这一块大概的讨论的是逆变换采样的问题，实际上这点非常有意思，他有着强烈的计算机背景</li>
</ul>
<blockquote>
<p>假定计算机可以模拟 <span class="math inline">\([0, 1]\)</span>上均匀分布的随机变量 U，U 称为伪随机数。基于此模拟任意的分布——也即<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%80%86%E5%8F%98%E6%8D%A2%E9%87%87%E6%A0%B7">逆变换采样</a></p>
</blockquote>
<ul>
<li>结合梁老师的课件和 wiki：</li>
</ul>
<p><span class="math display">\[
\text{For any function F which follows:}
\\ F(-\infty)=0\le F(X)\le F(+\infty)\\
\text{The distribution function for }y=F^{-1}{(x)}\text{ is }F(y)\\
\text{ where x follows uniformity distribution in } [0,1]
\]</span></p>
<ul>
<li>说人话就是，我先给定一个函数 F(X)，希望能够模拟符合 F(X) 分布的随机样本。首先验证 F(X) 是否符合极限条件，然后反解方程 <span class="math inline">\(F(F^{-1}(x))=x\)</span>，得到的 <span class="math inline">\(y = F^{-1}(X)\)</span> 即为符合 $F(y) $ 分布的随机变量。</li>
<li>P28，如下的例子，给出两个答案都是对的，这是因为：</li>
</ul>
<blockquote>
<p>对于均匀分布 X 和 1-X 同分布</p>
</blockquote>
<p><span class="math display">\[
F(x)=1-e^{-\lambda x}\\
F^{-1}(x)=\frac{ln^{(1-x)}}{-\lambda}\\
不过，老师给出的是 F(x)=\frac{ln^{(x)}}{-\lambda}
\]</span></p>
<blockquote>
<p>如果随机变量 <span class="math inline">\(X \sim U(0,1)\)</span>, 则 <span class="math inline">\(Y=\frac{-\ln X}{\lambda}\)</span> 服从参数为 <span class="math inline">\(\lambda\)</span> 的指数分布。 当 <span class="math inline">\(x \in(0,1)\)</span> 时, <span class="math inline">\(\frac{-\ln x}{\lambda}&gt;0\)</span>。所以, 当 <span class="math inline">\(y \leq 0\)</span> 时, <span class="math inline">\(F_{Y}(y)=P(Y \leq y)=0\)</span>，当 $y $ 时，<span class="math inline">\(\begin{aligned} F_{Y}(y) &amp;=P(Y \leq y)=P\left(\frac{-\ln X}{\lambda} \leq y\right)=P(\ln X \geq-\lambda y)=P\left(X \geq e^{-\lambda y}\right)=1-e^{-\lambda y} \end{aligned}\)</span>所以 <span class="math inline">\(Y \sim \operatorname{Exp}(\lambda)\)</span> 。</p>
</blockquote>
<ul>
<li>变量 X 符合某个分布 F(x)：<span class="math inline">\(P(X\le y)=F(y)\)</span>，变量 X 小于某个特定的值 y 的概率为 F(y)</li>
<li>P29，存在既非连续也非离散的随机变量</li>
</ul>
<h1 id="lecture-5-随机变量的数字特征期望与方差">Lecture 5 随机变量的数字特征：期望与方差</h1>
<ul>
<li>P3，期望的定义与存在条件——某种意义上的绝对收敛…</li>
</ul>
<p><span class="math display">\[
\int\limits_{-\infty}^{+\infty}p(x)|x|dx&lt;\infty
\]</span></p>
<ul>
<li>P9，方差的定义</li>
</ul>
<p><span class="math display">\[
Var(X)=E(X^2)-E(x)^2
\]</span></p>
<ul>
<li>P11，二项分布的期望与方差，<span class="math inline">\(np,np(1-p)\)</span></li>
<li>P13，伯努利分布( 两点分布 )的期望与方差，<span class="math inline">\(p,p(1-p)\)</span></li>
<li>P14，泊松分布的期望与方差，基于二项分布的极限是泊松分布来理解，<span class="math inline">\(np=\lambda,np(1-p)=\lambda\)</span></li>
<li>P14，几何分布的期望与方差，基于物理意义的理解，第一次出现成功实验的次数大概等于 <span class="math inline">\(\frac{1}{p}，Var(X)=\frac{1-p}{p^2}\)</span></li>
<li>P15，均匀分布，<span class="math inline">\(\frac{a+b}{2},\frac{(a-b)^2}{12}\)</span>，均匀分布的期望明显与分布的区间位置以及区间的长度有关</li>
<li>P15，指数分布，<span class="math inline">\(\frac{1}{\lambda},\frac{1}{\lambda^2}\)</span></li>
<li>P16，基于指数分布的期望计算积分</li>
<li>P17，正态分布的期望与方差，<span class="math inline">\(\mu,\sigma^2\)</span>，<span class="math inline">\(\varphi (x)=\frac{1}{\sqrt[]{2\pi} }e^{-\frac{x^2}{2}}\)</span></li>
</ul>
<blockquote>
<p><span class="math display">\[
f_{X}(x)=\frac{1}{\sqrt{2 \pi} \sigma} \mathrm{e}^{-(x-\mu)^{2} /\left(2 \sigma^{2}\right)}
\]</span></p>
</blockquote>
<ul>
<li><p>P18，基于正态分布的期望计算积分</p></li>
<li><p>P19，存在期望与方差均不存在的随机变量——柯西分布</p></li>
<li><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B9%BE%E4%BD%95%E5%88%86%E4%BD%88">几何分布</a>：</p>
<blockquote>
<p>在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/概率论">概率论</a>和<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/统计学">统计学</a>中，<strong>几何分布</strong>（英语：Geometric distribution）指的是以下两种离散型<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/機率分佈">概率分布</a>中的一种：</p>
<ul>
<li><p>在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/伯努利試驗">伯努利试验</a>中，得到一次成功所需要的试验次数<em>X</em>。<em>X</em>的值域是{ 1, 2, 3, ... }</p></li>
<li><p>在得到第一次成功之前所经历的失败次数<em>Y</em> = <em>X</em> − 1。<em>Y</em>的值域是{ 0, 1, 2, 3, ... }</p></li>
</ul>
<p>实际使用中指的是哪一个取决于惯例和使用方便。</p>
</blockquote></li>
<li><p>P21，切比雪夫不等式：与平均相差 <span class="math inline">\(k\)</span> 个标准差以上的值，数目不多于 <span class="math inline">\(\Large{\frac{1}{k^2}}\)</span></p></li>
</ul>
<p><span class="math display">\[
P(|X-E(X)| \geq b) \leq \frac{\operatorname{Var}(X)}{b^{2}}
\]</span></p>
<ul>
<li><p>P23，原点矩与中心矩的概念，期望是一阶原点矩，方差是二阶中心矩</p></li>
<li><p>期望的最小二乘性质：</p></li>
</ul>
<blockquote>
<p><span class="math display">\[
\min E\left((X-c)^{2}\right)=\operatorname{Var}(X), \text { where } c=E(x)
\]</span></p>
</blockquote>
<h1 id="lecture-6-多维随机变量">Lecture 6 多维随机变量</h1>
<ul>
<li>P2，随机向量和联合分布函数</li>
<li>P5，多维联合分布函数的性质：单调有界，右连续，非负</li>
<li>P6，二维非负性：主对角线之和减去次对角线之和非负</li>
<li>P9，边缘分布列</li>
<li>P12，连续型随机变量和联合密度函数，边际密度函数，编辑分布函数（联系 P9 边缘分布列）</li>
<li>P16，随机变量的独立性</li>
<li>P18，概率推断</li>
<li>P19，即便 <span class="math inline">\(p(x,y)=f(x)\times g(y)\)</span>，也不能断言 X, Y 独立分布</li>
<li>P21，独立同分布</li>
</ul>
<blockquote>
<p>在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/概率论">概率论</a>与<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/统计学">统计学</a>中，<strong>独立同分布</strong>（英语：<strong>Independent and identically distributed</strong>，或称独立同分配，缩写为iid、 i.i.d.、IID）是指一组<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/随机变量">随机变量</a>中每个变量的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/概率分布">概率分布</a>都相同，且这些随机变量互相<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/独立_(概率论)">独立</a></p>
</blockquote>
<ul>
<li>P23，X + Y 的分布</li>
<li>P24，独立随机变量的期望与方差</li>
</ul>
<p><span class="math display">\[
E(XY) = Cov(X,Y)+E(X)E(Y)=E(X)E(Y)
\]</span></p>
<p><span class="math display">\[
Var(X+Y)=Var(X)+Var(Y)+2\cdot Cov(X,Y)\\=Var(X)+Var(Y)+2\cdot Corr(X,Y)\cdot \sigma(X_1)\cdot \sigma(X_2)\\=Var(X)+Var(Y)
\]</span></p>
<ul>
<li>这样岂不是能得出 <span class="math inline">\(E(X^2)=E(X)^2\)</span> ，当然不是，因为随机变量两个都是 X 的话，二者当然是不独立的…</li>
<li>P26，多项分布</li>
<li>P27，三项分布的边际分布为二项分布</li>
<li>P28，n 维均匀分布</li>
<li>P29，二维正态分布</li>
<li>P31，二维正态分布的对称性，二维正态分布的边际密度即为一维正态分布——背住</li>
<li>P33，二维正态分布的向量表示</li>
<li>P34，多元正态分布</li>
</ul>
<h1 id="lecture-7-协方差相关系数与条件分布">Lecture 7 协方差、相关系数与条件分布</h1>
<ul>
<li>P1，协方差(Covariance)定义——从直观上来理解，协方差反应的是数据的相关程度，X 大于 E(X) 时，如果 Y 同时大于 E(Y)，X 小于 E(X) 时，如果 Y 同时小于 E(Y) ，则是正相关。如果变量之间不相关，那么协方差为 0；也可以理解为两个数据一同波动的程度。</li>
</ul>
<p><span class="math display">\[
Cov(X,Y)=E((X-E(X))(Y-E(Y))=E(XY)-E(X)E(Y)
\]</span></p>
<blockquote>
<p>反之，<span class="math inline">\(E(XY) = Cov(X,Y)+E(X)E(Y)\)</span></p>
</blockquote>
<ul>
<li>P2，协方差是内积运算</li>
<li>P2 + P3，协方差的性质——内积性</li>
</ul>
<blockquote>
<p><span class="math inline">\([\operatorname{Cov}(X, Y)]^{2} \leq \operatorname{Var}(X) \cdot \operatorname{Var}(Y)=\sigma_{X}{ }^{2} \cdot \sigma_{Y}^{2}\)</span></p>
</blockquote>
<ul>
<li>P6，相关系数：相关系数是将随机变量做方差为 1 的标准化后的协方差</li>
</ul>
<p><span class="math display">\[
Corr(X,Y)=Cov(\frac{X}{\sigma(X)},\frac{Y}{\sigma(Y)})=\frac{Cov(X,Y)}{\sigma(X)\cdot \sigma(Y)}——内积的性质
\]</span></p>
<ul>
<li>可以证明 <span class="math inline">\(\rho=1(\rho=-1)\)</span> 当且仅当存在一个正的 (负的) 常数 <span class="math inline">\(c\)</span>， 使得</li>
</ul>
<p><span class="math display">\[
Y-\mathrm{E}[Y]=c(X-\mathrm{E}[X])
\]</span></p>
<ul>
<li><p>P7，<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%9F%AF%E8%A5%BF%E2%80%94%E6%96%BD%E7%93%A6%E8%8C%A8%E4%B8%8D%E7%AD%89%E5%BC%8F/4699871">Cauchy-Schwarz 不等式</a>——完全不能理解讲义的意思（梁老师貌似写错了…） <span class="math display">\[
对于内积运算：(x,y)^2\le (x,x)\cdot (y,y)\\\text{协方差是一种内积运算}：Cov(X,X)=Var(X)
\]</span></p></li>
<li><p>P8，协方差的性质应用如果变量之间不相关，那么协方差为 0，此处是独立同分布，独立是比不相关更强的条件</p></li>
<li><p>P9，线性相关系数：相关系数反应的是随机变量之间在线性关系意义下的相关程度，所以也称为（线性）相关系数</p></li>
<li><p>P9，所谓的不相关是指不存在（线性）相关的关系，相关系数并不能充分表达非线性的相关关系</p></li>
<li><p>P14，二元正态分布的边缘分布为一元正态分布（反之不然），且对于二元正态分布而言，独立等价于不相关</p></li>
</ul>
<blockquote>
<p><span class="math display">\[
f(x, y)=\left(2 \pi \sigma_{1} \sigma_{2} \sqrt{1-\rho^{2}}\right)^{-1} \exp \left[-\frac{1}{2\left(1-\rho^{2}\right)}\left(\frac{\left(x-\mu_{1}\right)^{2}}{\sigma_{1}^{2}}-\frac{2 \rho\left(x-\mu_{1}\right)\left(y-\mu_{2}\right)}{\sigma_{1} \sigma_{2}}+\frac{\left(y-\mu_{2}\right)^{2}}{\sigma_{2}^{2}}\right)\right]
\]</span> 其中 <span class="math inline">\(\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}, \rho\)</span> 都是常数, 我们称 <span class="math inline">\(\left(X_{1}, X_{2}\right)\)</span> 服从参数为 <span class="math inline">\(\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}, \rho\)</span> 的二维正态分布, 常把这个分布记作 <span class="math inline">\(N\left(\mu_{1}, \mu_{2}, \sigma_{1}^{2}, \sigma_{2}^{2}, \rho\right)\)</span> ) 。 <span class="math inline">\(\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}, \rho\)</span> 的范围分别为 <span class="math inline">\(-\infty&lt;\mu_{1}&lt;+\infty ;-\infty&lt;\mu_{2}&lt;+\infty ;-1&lt;\rho&lt;1\)</span> <span class="math inline">\(\sigma_{1}&gt;0 ; \sigma_{2}&gt;0\)</span> 。这个函数在三维空间中的图像是一个椭圆切面的钟倒扣在 <span class="math inline">\(O x_{1} x_{2}\)</span> 平面上，其中心在 <span class="math inline">\(\left(\mu_{1}, \mu_{2}\right)\)</span> 点。</p>
<p>二维随机变量 <span class="math inline">\((X, Y)\)</span> 的联合密度函数为 <span class="math display">\[
p(x, y)=\frac{1}{6 \sqrt{3} \pi} \exp \left\{\frac{-2}{3}\left[\frac{x^{2}}{9}+\frac{x y-x}{6}+\frac{(y-1)^{2}}{4}\right]\right\} \text {, }
\]</span> 令 <span class="math inline">\(U=3 X+1, V=5-2 Y\)</span>, 则 <span class="math inline">\(\operatorname{Corr}(U, V)=()\)</span> 这个题最麻烦的地方在于，需要看出： <span class="math inline">\((X, Y) \sim N\left(0,1,3^{2}, 2^{2},-0.5\right)\)</span></p>
</blockquote>
<ul>
<li>P15，随机变量和的期望</li>
</ul>
<p><span class="math display">\[
Var(X+Y)=Var(X)+Var(Y)+2\cdot Cov(X,Y)=Var(X)+Var(Y)+2\cdot Corr(X,Y)\cdot \sigma(X_1)\cdot \sigma(X_2)
\]</span></p>
<blockquote>
<p>考虑到 cov 是内积运算，其实这个公式就是平方和公式</p>
<p>更近一步，考虑下式： <span class="math display">\[
X_1,X_2 \quad i.i.d.\\\text{Hence } Var(X_1+X_2)=Var(X_1)+Var(X_2)\\Var(2X_1)=Var(X_1)+Var(X_1)+2\cdot 1\cdot Var(X_1)=4\cdot Var(X_1)
\]</span></p>
</blockquote>
<ul>
<li>P16，随机变量函数的期望</li>
<li>P19，条件分布，类似于边缘分布</li>
<li>P20，例子——离散分布的条件分布，结合 P21 页泊松分布的可加性理解</li>
</ul>
<blockquote>
<p><strong>可加性</strong></p>
<ol type="1">
<li><p>二项分布</p>
<p><span class="math inline">\(X \sim B(m, p),Y \sim B(n, p), X, Y\)</span> 相互独立, 则 <span class="math inline">\(X+Y \sim B(m+n, p)\)</span></p></li>
<li><p>泊松分布</p>
<p><span class="math inline">\(X\)</span> 服从参数为 <span class="math inline">\(\lambda_{1}\)</span> 的泊松分布, <span class="math inline">\(Y\)</span> 服从参数为 <span class="math inline">\(\lambda_{2}\)</span> 的泊松分布, <span class="math inline">\(X\)</span> 与 <span class="math inline">\(Y\)</span> 相互独立, <span class="math inline">\(Z=X+Y\)</span>, 则 <span class="math inline">\(Z\)</span> 服从参数为 <span class="math inline">\(\lambda_{1}+\lambda_{2}\)</span> 的泊松分布</p></li>
<li><p>正态分布</p>
<p>如果 <span class="math inline">\(X \sim N\left(\mu, \sigma^{2}\right)\)</span> 且a与b是实数, 那么 <span class="math inline">\(a X+b \sim N\left(a \mu+b,(a \sigma)^{2}\right)\)</span></p>
<p>如果 <span class="math inline">\(X \sim N\left(\mu_{X}, \sigma_{X}^{2}\right)\)</span> 与 <span class="math inline">\(Y \sim N\left(\mu_{Y}, \sigma_{Y}^{2}\right)\)</span> 是统计独立的正态随机变量, 那么:</p>
<p>它们的和也满足正态分布 <span class="math inline">\(U=X+Y \sim N\left(\mu_{X}+\mu_{Y}, \sigma_{X}^{2}+\sigma_{Y}^{2}\right)\)</span></p>
<p>它们的差也满足正态分布 <span class="math inline">\(V=X-Y \sim N\left(\mu_{X}-\mu_{Y}, \sigma_{X}^{2}+\sigma_{Y}^{2}\right)\)</span>.</p>
<p><span class="math inline">\(X\)</span> 与 <span class="math inline">\(Y\)</span> 方差相等时， <span class="math inline">\(U\)</span> 与 <span class="math inline">\(V\)</span> 二者独立。</p>
<p>实际上如果方差不相等，也能构造独立，比如：</p>
<blockquote>
<p>二维随机变量 <span class="math inline">\((X, Y) \sim N\left(\mathbf{0}, \mathbf{0}, 1, \frac{1}{4}, \frac{1}{3}\right)\)</span>, 设 <span class="math inline">\(U=X-2 Y\)</span> 和 <span class="math inline">\(V=X+2 Y\)</span> <span class="math display">\[
\begin{array}{l}\operatorname{Cov}(U, V)=\operatorname{Cov}(\boldsymbol{X}-2 \boldsymbol{Y}, \boldsymbol{X}+2 \boldsymbol{Y})\\
=\operatorname{Cov}(X, X)+2 \operatorname{Cov}(X, Y)-2 \operatorname{Cov}(X, Y)-4 \operatorname{Cov}(Y, Y) \\
=\operatorname{Var}(X)-4 \operatorname{Var}(\boldsymbol{Y})=0
\end{array}
\]</span> 所以 <span class="math inline">\(U, V\)</span> 独立</p>
</blockquote></li>
<li><p>卡方分布</p>
<p>若 <span class="math inline">\(X_{i} \sim \chi^{2}\left(n_{i}\right), \quad i=1,2, \cdots, n\)</span> ，且 <span class="math inline">\(X_{i}\)</span> 独立，则 <span class="math display">\[
\sum_{i=1}^{n} \chi^{2}\left(n_{i}\right) \sim \chi^{2}\left(\sum_{i=1}^{n} n_{i}\right)
\]</span> 不可加：0–1 分布、几何分布、均匀分布、指数分布、t 分布</p></li>
</ol>
</blockquote>
<ul>
<li>P21，相互独立条件下，泊松分布可加。相互独立且 p 相同的条件下，二项分布可加</li>
<li>P23，给定条件下，连续随机变量的条件分布函数与条件密度函数</li>
</ul>
<p><span class="math display">\[
P(x|y)=\frac{P(x,y)}{P_Y(y)}
\]</span></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9B%99%E9%87%8D%E6%9C%9F%E6%9C%9B%E5%80%BC%E5%AE%9A%E7%90%86">重期望定理</a></li>
</ul>
<blockquote>
<p><span class="math inline">\(\mathrm{E}(X)=\mathrm{E}(\mathrm{E}(X \mid Y))\)</span> <span class="math display">\[
\begin{aligned}
\mathrm{E}(\mathrm{E}(X \mid Y)) &amp;=\sum_{y} \mathrm{E}(X \mid Y=y) \cdot \mathrm{P}(Y=y) \\
&amp;=\sum_{y}\left(\sum_{x} x \cdot \mathrm{P}(X=x \mid Y=y)\right) \cdot \mathrm{P}(Y=y) \\
&amp;=\sum_{y} \sum_{x} x \cdot \mathrm{P}(X=x \mid Y=y) \cdot \mathrm{P}(Y=y) \\
&amp;=\sum_{y} \sum_{x} x \cdot \mathrm{P}(Y=y \mid X=x) \cdot \mathrm{P}(X=x) \\
&amp;=\sum_{x} \sum_{y} x \cdot \mathrm{P}(Y=y \mid X=x) \cdot \mathrm{P}(X=x) \\
&amp;=\sum_{x} x \cdot \mathrm{P}(X=x) \cdot\left(\sum_{y} \mathrm{P}(Y=y \mid X=x)\right) \\
&amp;=\sum_{x} x \cdot \mathrm{P}(X=x) \\
&amp;=\mathrm{E}(X)
\end{aligned}
\]</span></p>
</blockquote>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2022%E6%98%A5%E5%AD%A3/">2022春季</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-62b11572b25ab3ab" async="async"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/02/23/Lecture/2022%20Spring/Advanced_word_power/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.imgdb.cn/item/61ed143f2ab3f51d911d4294.jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Oscar Rodrigo Hernandez Panczenko (P0GQ95huhBo).jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Advanced Word Power Lecture Note</div></div></a></div><div class="next-post pull-right"><a href="/2022/02/23/CS/%E5%85%A8%E6%A0%88%E5%BC%80%E5%8F%91/JS_oop/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Gonzalo P (sRWFBez6xOg).jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Oscar Rodrigo Hernandez Panczenko (P0GQ95huhBo).jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">JavaScript oop &amp; JavaScript in Web Browser</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/06/06/Lecture/2022%20Spring/statistic/" title="Statistics"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Jaromír Kavan (L1DksU0Mrd4)(1).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-06</div><div class="title">Statistics</div></div></a></div><div><a href="/2022/04/02/Lecture/2022%20Spring/distribution/" title="Distribution Is All U Need"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Anna Goncharova (7e_gFC2Ce04).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-02</div><div class="title">Distribution Is All U Need</div></div></a></div><div><a href="/2022/03/22/Lecture/2022%20Spring/Computer_graphics/" title="Computer Graphics"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Tobias Reich (aJDb9v3CIkY).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-22</div><div class="title">Computer Graphics</div></div></a></div><div><a href="/2022/03/31/%E5%87%BA%E5%9B%BD/%E9%A1%B9%E8%84%8A%E8%BD%A9%E5%BF%97/" title="临别项脊轩"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Marc Marchal (o9sQxsixlng).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-31</div><div class="title">临别项脊轩</div></div></a></div><div><a href="/2022/05/25/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%94%E9%83%A8/" title="清华园日记——第五部"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhaochenyang20.github.io/pic/embed/5_31_1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-25</div><div class="title">清华园日记——第五部</div></div></a></div><div><a href="/2022/02/08/%E9%9A%8F%E7%AC%94/%E6%80%BB%E7%BB%93/Say%20Something%20for%20Spring%202022/" title="Say Something for Spring 2022"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.imgdb.cn/item/620540f92ab3f51d91b65009.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-08</div><div class="title">Say Something for Spring 2022</div></div></a></div><div><a href="/2022/04/02/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%B8%89%E9%83%A8/" title="清华园日记——第三部"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-02</div><div class="title">清华园日记——第三部</div></div></a></div><div><a href="/2022/02/20/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%8C%E9%83%A8/" title="清华园日记——第二部"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic.imgdb.cn/item/61f0fc612ab3f51d9172f963.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-20</div><div class="title">清华园日记——第二部</div></div></a></div><div><a href="/2022/06/16/Lecture/2022%20Spring/%E8%AF%B7%E4%BB%A5%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97%E5%91%BC%E5%94%A4%E6%88%91/" title="我们为什么会选择社会化抚养"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://raw.githubusercontent.com/zhaochenyang20/ivue_wallpaper/main/ivue_desktop/Photo by Pang Yuhao (J558nCHFYmY)(2).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-16</div><div class="title">我们为什么会选择社会化抚养</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#readme"><span class="toc-number">1.</span> <span class="toc-text">readme</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%A7%82%E5%BF%B5"><span class="toc-number">2.</span> <span class="toc-text">课程学习的观念</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture-1-%E5%BC%95%E8%A8%80"><span class="toc-number">3.</span> <span class="toc-text">Lecture 1 引言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture-2-%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><span class="toc-number">4.</span> <span class="toc-text">Lecture 2 条件概率</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lec-3-%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F"><span class="toc-number">5.</span> <span class="toc-text">Lec 3 离散型随机变量</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture-4-%E8%BF%9E%E7%BB%AD%E6%80%A7%E7%A6%BB%E6%95%A3%E5%8F%98%E9%87%8F"><span class="toc-number">6.</span> <span class="toc-text">Lecture 4 连续性离散变量</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture-5-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81%E6%9C%9F%E6%9C%9B%E4%B8%8E%E6%96%B9%E5%B7%AE"><span class="toc-number">7.</span> <span class="toc-text">Lecture 5 随机变量的数字特征：期望与方差</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture-6-%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F"><span class="toc-number">8.</span> <span class="toc-text">Lecture 6 多维随机变量</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture-7-%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E4%B8%8E%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83"><span class="toc-number">9.</span> <span class="toc-text">Lecture 7 协方差、相关系数与条件分布</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background: ＃0096FF"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Eren Zhao</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><script type="text/javascript" id="maid-script" src="https://unpkg.com/mermaid@undefined/dist/mermaid.min.js?v=undefined"></script><script>if (window.mermaid) {
  var options = JSON.parse(document.getElementById('maid-script').getAttribute('mermaidoptioins'));
  mermaid.initialize(options);
}</script></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库正在艰难运行</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '978121c7b834efdd76be',
      clientSecret: '59b40e8f39a1c33db5a2c891771086164b9575c4',
      repo: 'zhaochenyang20.github.io',
      owner: 'zhaochenyang20',
      admin: ['zhaochenyang20'],
      id: 'acf3f2aa40e01a6e77e2fd6f6da37ee0',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/"});</script></body></html>